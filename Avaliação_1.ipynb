{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Avaliação_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Le4o/topicos-avancados-ic/blob/main/Avalia%C3%A7%C3%A3o_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph2GsBsm71kL"
      },
      "source": [
        "# Avaliação 1\n",
        "#### Exercício da matéria de Tópicos Avançados em Inteligência Computacional\n",
        "\n",
        "Grupo:\n",
        "- João Victor de Sledz Bulhões\n",
        "- Leonardo de Andrade Santana\n",
        "- Lis da Silva Azevedo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCjtVa-V8-Qq"
      },
      "source": [
        "### Definição do Exercício\n",
        "Utilizaremos o banco de dados do Human Activity Recognition with Smartphones, que foi construído a partir das gravações dos participantes do estudo realizando atividades da vida diária enquanto carregavam um smartphone com sensores inerciais embutidos. Para cada registro no conjunto de dados, é fornecido:\n",
        "\n",
        "- Aceleração triaxial do acelerômetro (aceleração total) e a aceleração corporal estimada.\n",
        "\n",
        "- Velocidade angular triaxial do giroscópio.\n",
        "\n",
        "- Um vetor de 561 atributos com variáveis de domínio de tempo e frequência.\n",
        "\n",
        "- O rótulo da atividade.\n",
        "\n",
        "### Objetivo:\n",
        "* Construir um modelo robusto para classificação das atividades diárias, utilizando o banco de dados fornecido, em uma das seis ações disponíveis:\n",
        "> 1. caminhar;\n",
        "> 2. subir escadas;\n",
        "> 3. descer escadas;\n",
        "> 4. sentar;\n",
        "> 5. ficar em pé;\n",
        "> 6. deitar.\n",
        "\n",
        "* Desenvolver 4 modelos, utilizando:\n",
        "> 1. Multi-Layer Perceptron (MLP)\n",
        "> 2. Convolutional Neural Network (CNN)\n",
        "> 3. Recurrent Neural Network (RNN)\n",
        "> 4. Arquitetura hibrida com a combinação das redes anteriore\n",
        "\n",
        "* Considere a divisão entre treinamento, validação e teste de 50%, 25% e 25%, respectivamente.\n",
        "\n",
        "* Utilizar como métricas: **precision, recall, specificity,\n",
        "F1-Score e accuracy**, evidenciando que o modelo não sofreu de **over/underfitting**.\n",
        "\n",
        "### Observação: \n",
        "*   *Apresentação de métricas, gráficos, são essenciais para entendimento dos modelos e justificativas.*\n",
        "*   *Compare ao final em uma tabela e apresente que técnica obteve os melhores\n",
        "resultados, discutindo-os à luz de seu conhecimento sobre o assunto, discutindo\n",
        "se eram resultados esperados, se estão adequados, e os porquês.*\n",
        "\n",
        "### Opcionais:\n",
        "\n",
        "*   A utilização de redes neurais baseadas em transformers é opcional e adicionará **1,0 ponto extra** ao projeto.\n",
        "*   A utilização de pré-processamento das séries com Wavelets OU transformadas de Fourier adicionará **1,0 ponto extra** ao projeto.\n",
        "\n",
        "\n",
        "### Link:\n",
        "\n",
        "* [Mais informações sobre os recursos estão disponíveis no site](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UF0cRGhDgiY",
        "outputId": "d73281e3-a3b4-41b3-99d7-531fc71bdd1b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive/Datasets"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/Datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9Y0uE6G8Cq7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPcy7yBBJkXe"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import keras_metrics\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from tensorflow.keras.layers import Dense, Dropout, MaxPooling1D, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cc1HvZ173f4"
      },
      "source": [
        "## Carregando os dados\n",
        "\n",
        "O dataset fornecido é segmentado em **70% treino e 30% teste**, porém a atividade pede para segmentar em: **50% treino, 25% validação e 25% teste.** Então nos primeiramente juntamos os dados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yALQSUMD5W4",
        "outputId": "41a284db-4630-4a96-fbff-572380814be9"
      },
      "source": [
        "# Carregando os dados diretamente dos csvs do Human Activity Recognition with Smartphones\n",
        "train_data = pd.read_csv('./uci_har_csvs/train.csv')\n",
        "test_data = pd.read_csv('./uci_har_csvs/test.csv')\n",
        "\n",
        "print(f'Shape of train data is: {train_data.shape}\\nShape of test data is: {test_data.shape}')\n",
        "\n",
        "data = train_data.append(test_data)\n",
        "data.shape\n",
        "\n",
        "print(f'Shape of combined data is {data.shape}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train data is: (7352, 563)\n",
            "Shape of test data is: (2947, 563)\n",
            "Shape of combined data is (10299, 563)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGe5x0Dw8IMt"
      },
      "source": [
        "## Analise inicial dos dados\n",
        "\n",
        "O dataset possui 6 classes, sendo elas:\n",
        "\n",
        "\n",
        "1.   Walking downstairs\n",
        "2.   Walking Upstairs\n",
        "3.   Walking\n",
        "4.   Sitting\n",
        "5.   Stading \n",
        "6.   Laying\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idSZzsaY20Yn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "fd4274a4-fc1f-4644-d88f-2840c561acf8"
      },
      "source": [
        "class_count = len(data['Activity'].unique())\n",
        "data['Activity'].value_counts().sort_values().plot(kind = 'bar', color = 'pink')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8327b1cb50>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6laf9fa7L6w"
      },
      "source": [
        "## Segmentação do Dataset\n",
        "\n",
        "50% treino, 25% validação e 25% teste\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRW0Ytg_2hap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "c5d6a74a-4193-444e-a048-7d55f157f29a"
      },
      "source": [
        "train, validate, test = \\\n",
        "              np.split(data.sample(frac=1, random_state=42), \n",
        "                       [int(.5*len(data)), int(.75*len(data))])\n",
        "              \n",
        "print(f'Shape of train data is {train.shape}')\n",
        "print(f'Shape of validation data is {validate.shape}')\n",
        "print(f'Shape of test data is {test.shape}')\n",
        "validate.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train data is (5149, 563)\n",
            "Shape of validation data is (2575, 563)\n",
            "Shape of test data is (2575, 563)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tBodyAcc-mean()-X</th>\n",
              "      <th>tBodyAcc-mean()-Y</th>\n",
              "      <th>tBodyAcc-mean()-Z</th>\n",
              "      <th>tBodyAcc-std()-X</th>\n",
              "      <th>tBodyAcc-std()-Y</th>\n",
              "      <th>tBodyAcc-std()-Z</th>\n",
              "      <th>tBodyAcc-mad()-X</th>\n",
              "      <th>tBodyAcc-mad()-Y</th>\n",
              "      <th>tBodyAcc-mad()-Z</th>\n",
              "      <th>tBodyAcc-max()-X</th>\n",
              "      <th>tBodyAcc-max()-Y</th>\n",
              "      <th>tBodyAcc-max()-Z</th>\n",
              "      <th>tBodyAcc-min()-X</th>\n",
              "      <th>tBodyAcc-min()-Y</th>\n",
              "      <th>tBodyAcc-min()-Z</th>\n",
              "      <th>tBodyAcc-sma()</th>\n",
              "      <th>tBodyAcc-energy()-X</th>\n",
              "      <th>tBodyAcc-energy()-Y</th>\n",
              "      <th>tBodyAcc-energy()-Z</th>\n",
              "      <th>tBodyAcc-iqr()-X</th>\n",
              "      <th>tBodyAcc-iqr()-Y</th>\n",
              "      <th>tBodyAcc-iqr()-Z</th>\n",
              "      <th>tBodyAcc-entropy()-X</th>\n",
              "      <th>tBodyAcc-entropy()-Y</th>\n",
              "      <th>tBodyAcc-entropy()-Z</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,4</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,4</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,4</th>\n",
              "      <th>tBodyAcc-correlation()-X,Y</th>\n",
              "      <th>tBodyAcc-correlation()-X,Z</th>\n",
              "      <th>tBodyAcc-correlation()-Y,Z</th>\n",
              "      <th>...</th>\n",
              "      <th>fBodyBodyAccJerkMag-entropy()</th>\n",
              "      <th>fBodyBodyAccJerkMag-maxInds</th>\n",
              "      <th>fBodyBodyAccJerkMag-meanFreq()</th>\n",
              "      <th>fBodyBodyAccJerkMag-skewness()</th>\n",
              "      <th>fBodyBodyAccJerkMag-kurtosis()</th>\n",
              "      <th>fBodyBodyGyroMag-mean()</th>\n",
              "      <th>fBodyBodyGyroMag-std()</th>\n",
              "      <th>fBodyBodyGyroMag-mad()</th>\n",
              "      <th>fBodyBodyGyroMag-max()</th>\n",
              "      <th>fBodyBodyGyroMag-min()</th>\n",
              "      <th>fBodyBodyGyroMag-sma()</th>\n",
              "      <th>fBodyBodyGyroMag-energy()</th>\n",
              "      <th>fBodyBodyGyroMag-iqr()</th>\n",
              "      <th>fBodyBodyGyroMag-entropy()</th>\n",
              "      <th>fBodyBodyGyroMag-maxInds</th>\n",
              "      <th>fBodyBodyGyroMag-meanFreq()</th>\n",
              "      <th>fBodyBodyGyroMag-skewness()</th>\n",
              "      <th>fBodyBodyGyroMag-kurtosis()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-mean()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-std()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-mad()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-max()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-min()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-sma()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-energy()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-iqr()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-entropy()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-maxInds</th>\n",
              "      <th>fBodyBodyGyroJerkMag-meanFreq()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
              "      <th>angle(tBodyAccMean,gravity)</th>\n",
              "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
              "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
              "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
              "      <th>angle(X,gravityMean)</th>\n",
              "      <th>angle(Y,gravityMean)</th>\n",
              "      <th>angle(Z,gravityMean)</th>\n",
              "      <th>subject</th>\n",
              "      <th>Activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2117</th>\n",
              "      <td>0.274369</td>\n",
              "      <td>-0.016706</td>\n",
              "      <td>-0.110229</td>\n",
              "      <td>-0.991515</td>\n",
              "      <td>-0.989040</td>\n",
              "      <td>-0.978536</td>\n",
              "      <td>-0.992510</td>\n",
              "      <td>-0.990249</td>\n",
              "      <td>-0.980843</td>\n",
              "      <td>-0.936067</td>\n",
              "      <td>-0.561457</td>\n",
              "      <td>-0.812424</td>\n",
              "      <td>0.841441</td>\n",
              "      <td>0.691739</td>\n",
              "      <td>0.824627</td>\n",
              "      <td>-0.989752</td>\n",
              "      <td>-0.999926</td>\n",
              "      <td>-0.999935</td>\n",
              "      <td>-0.999490</td>\n",
              "      <td>-0.994133</td>\n",
              "      <td>-0.991564</td>\n",
              "      <td>-0.983694</td>\n",
              "      <td>-0.570835</td>\n",
              "      <td>-0.632256</td>\n",
              "      <td>-0.525435</td>\n",
              "      <td>0.194450</td>\n",
              "      <td>-0.146492</td>\n",
              "      <td>-0.041534</td>\n",
              "      <td>0.385220</td>\n",
              "      <td>0.146668</td>\n",
              "      <td>0.008702</td>\n",
              "      <td>0.117522</td>\n",
              "      <td>0.316987</td>\n",
              "      <td>0.049494</td>\n",
              "      <td>0.002990</td>\n",
              "      <td>0.077043</td>\n",
              "      <td>-0.040535</td>\n",
              "      <td>-0.326617</td>\n",
              "      <td>-0.124434</td>\n",
              "      <td>-0.467705</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.189798</td>\n",
              "      <td>-0.435028</td>\n",
              "      <td>-0.826468</td>\n",
              "      <td>-0.983336</td>\n",
              "      <td>-0.983446</td>\n",
              "      <td>-0.979036</td>\n",
              "      <td>-0.988786</td>\n",
              "      <td>-0.996133</td>\n",
              "      <td>-0.983336</td>\n",
              "      <td>-0.999768</td>\n",
              "      <td>-0.973804</td>\n",
              "      <td>-0.651509</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.200696</td>\n",
              "      <td>-0.692462</td>\n",
              "      <td>-0.925401</td>\n",
              "      <td>-0.990613</td>\n",
              "      <td>-0.989842</td>\n",
              "      <td>-0.989335</td>\n",
              "      <td>-0.990264</td>\n",
              "      <td>-0.995010</td>\n",
              "      <td>-0.990613</td>\n",
              "      <td>-0.999922</td>\n",
              "      <td>-0.988997</td>\n",
              "      <td>-0.923452</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.165418</td>\n",
              "      <td>-0.227327</td>\n",
              "      <td>-0.592258</td>\n",
              "      <td>-0.031017</td>\n",
              "      <td>-0.068529</td>\n",
              "      <td>0.222656</td>\n",
              "      <td>-0.171256</td>\n",
              "      <td>0.365294</td>\n",
              "      <td>-0.846661</td>\n",
              "      <td>-0.004809</td>\n",
              "      <td>11</td>\n",
              "      <td>LAYING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2937</th>\n",
              "      <td>0.260018</td>\n",
              "      <td>-0.008491</td>\n",
              "      <td>-0.117588</td>\n",
              "      <td>-0.935685</td>\n",
              "      <td>-0.670521</td>\n",
              "      <td>-0.875247</td>\n",
              "      <td>-0.959882</td>\n",
              "      <td>-0.805597</td>\n",
              "      <td>-0.907493</td>\n",
              "      <td>-0.892596</td>\n",
              "      <td>-0.146449</td>\n",
              "      <td>-0.774665</td>\n",
              "      <td>0.710398</td>\n",
              "      <td>0.541556</td>\n",
              "      <td>0.691246</td>\n",
              "      <td>-0.910007</td>\n",
              "      <td>-0.997606</td>\n",
              "      <td>-0.978016</td>\n",
              "      <td>-0.991313</td>\n",
              "      <td>-0.995422</td>\n",
              "      <td>-0.989595</td>\n",
              "      <td>-0.963853</td>\n",
              "      <td>-0.310086</td>\n",
              "      <td>-0.398456</td>\n",
              "      <td>-0.248864</td>\n",
              "      <td>-0.508756</td>\n",
              "      <td>0.476951</td>\n",
              "      <td>-0.460860</td>\n",
              "      <td>0.392226</td>\n",
              "      <td>-0.604299</td>\n",
              "      <td>0.591770</td>\n",
              "      <td>-0.713939</td>\n",
              "      <td>0.839213</td>\n",
              "      <td>-0.252033</td>\n",
              "      <td>0.355529</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.296486</td>\n",
              "      <td>-0.012320</td>\n",
              "      <td>-0.867214</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.476360</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.455206</td>\n",
              "      <td>0.384570</td>\n",
              "      <td>0.087227</td>\n",
              "      <td>-0.512505</td>\n",
              "      <td>-0.269562</td>\n",
              "      <td>-0.408939</td>\n",
              "      <td>-0.192944</td>\n",
              "      <td>-0.049099</td>\n",
              "      <td>-0.512505</td>\n",
              "      <td>-0.740628</td>\n",
              "      <td>-0.801698</td>\n",
              "      <td>0.130729</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.259452</td>\n",
              "      <td>0.265055</td>\n",
              "      <td>-0.064927</td>\n",
              "      <td>-0.929913</td>\n",
              "      <td>-0.863376</td>\n",
              "      <td>-0.907363</td>\n",
              "      <td>-0.843969</td>\n",
              "      <td>-0.985603</td>\n",
              "      <td>-0.929913</td>\n",
              "      <td>-0.993913</td>\n",
              "      <td>-0.935197</td>\n",
              "      <td>-0.419270</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.563006</td>\n",
              "      <td>0.783258</td>\n",
              "      <td>0.551519</td>\n",
              "      <td>0.351286</td>\n",
              "      <td>0.079468</td>\n",
              "      <td>0.329166</td>\n",
              "      <td>0.006809</td>\n",
              "      <td>-0.885412</td>\n",
              "      <td>0.113755</td>\n",
              "      <td>0.100170</td>\n",
              "      <td>16</td>\n",
              "      <td>SITTING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6867</th>\n",
              "      <td>0.278964</td>\n",
              "      <td>-0.016177</td>\n",
              "      <td>-0.112617</td>\n",
              "      <td>-0.986395</td>\n",
              "      <td>-0.993402</td>\n",
              "      <td>-0.996253</td>\n",
              "      <td>-0.987809</td>\n",
              "      <td>-0.994375</td>\n",
              "      <td>-0.995559</td>\n",
              "      <td>-0.935219</td>\n",
              "      <td>-0.566172</td>\n",
              "      <td>-0.826331</td>\n",
              "      <td>0.838379</td>\n",
              "      <td>0.692073</td>\n",
              "      <td>0.845662</td>\n",
              "      <td>-0.992035</td>\n",
              "      <td>-0.999849</td>\n",
              "      <td>-0.999965</td>\n",
              "      <td>-0.999920</td>\n",
              "      <td>-0.989898</td>\n",
              "      <td>-0.995405</td>\n",
              "      <td>-0.992992</td>\n",
              "      <td>-0.391655</td>\n",
              "      <td>-0.668624</td>\n",
              "      <td>-0.735404</td>\n",
              "      <td>0.074098</td>\n",
              "      <td>-0.024003</td>\n",
              "      <td>-0.086759</td>\n",
              "      <td>-0.050424</td>\n",
              "      <td>0.497133</td>\n",
              "      <td>-0.308945</td>\n",
              "      <td>0.436123</td>\n",
              "      <td>-0.284634</td>\n",
              "      <td>0.562480</td>\n",
              "      <td>-0.303941</td>\n",
              "      <td>0.243113</td>\n",
              "      <td>-0.238292</td>\n",
              "      <td>-0.560531</td>\n",
              "      <td>-0.482763</td>\n",
              "      <td>0.529234</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.746032</td>\n",
              "      <td>0.201563</td>\n",
              "      <td>-0.661723</td>\n",
              "      <td>-0.919496</td>\n",
              "      <td>-0.963026</td>\n",
              "      <td>-0.936948</td>\n",
              "      <td>-0.955237</td>\n",
              "      <td>-0.922671</td>\n",
              "      <td>-0.973526</td>\n",
              "      <td>-0.963026</td>\n",
              "      <td>-0.998002</td>\n",
              "      <td>-0.980297</td>\n",
              "      <td>-0.508129</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.242515</td>\n",
              "      <td>0.564836</td>\n",
              "      <td>0.361085</td>\n",
              "      <td>-0.997792</td>\n",
              "      <td>-0.997197</td>\n",
              "      <td>-0.997178</td>\n",
              "      <td>-0.997628</td>\n",
              "      <td>-0.995845</td>\n",
              "      <td>-0.997792</td>\n",
              "      <td>-0.999990</td>\n",
              "      <td>-0.997452</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.650794</td>\n",
              "      <td>0.391506</td>\n",
              "      <td>-0.412803</td>\n",
              "      <td>-0.785954</td>\n",
              "      <td>0.126507</td>\n",
              "      <td>0.229589</td>\n",
              "      <td>-0.420273</td>\n",
              "      <td>0.306465</td>\n",
              "      <td>0.496486</td>\n",
              "      <td>-0.614039</td>\n",
              "      <td>-0.381354</td>\n",
              "      <td>29</td>\n",
              "      <td>LAYING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>0.183580</td>\n",
              "      <td>-0.127213</td>\n",
              "      <td>-0.053418</td>\n",
              "      <td>0.066369</td>\n",
              "      <td>0.175940</td>\n",
              "      <td>-0.392213</td>\n",
              "      <td>0.024724</td>\n",
              "      <td>0.176251</td>\n",
              "      <td>-0.373970</td>\n",
              "      <td>0.026905</td>\n",
              "      <td>-0.011366</td>\n",
              "      <td>-0.414110</td>\n",
              "      <td>-0.061307</td>\n",
              "      <td>-0.120410</td>\n",
              "      <td>0.453433</td>\n",
              "      <td>0.075900</td>\n",
              "      <td>-0.429020</td>\n",
              "      <td>-0.711465</td>\n",
              "      <td>-0.826533</td>\n",
              "      <td>-0.026840</td>\n",
              "      <td>-0.006198</td>\n",
              "      <td>-0.409776</td>\n",
              "      <td>0.363369</td>\n",
              "      <td>0.033249</td>\n",
              "      <td>0.151558</td>\n",
              "      <td>-0.422318</td>\n",
              "      <td>0.161796</td>\n",
              "      <td>0.187022</td>\n",
              "      <td>-0.033507</td>\n",
              "      <td>-0.540551</td>\n",
              "      <td>0.463843</td>\n",
              "      <td>-0.051249</td>\n",
              "      <td>-0.049775</td>\n",
              "      <td>-0.322750</td>\n",
              "      <td>0.332125</td>\n",
              "      <td>-0.213743</td>\n",
              "      <td>-0.117904</td>\n",
              "      <td>-0.191380</td>\n",
              "      <td>0.028687</td>\n",
              "      <td>0.224921</td>\n",
              "      <td>...</td>\n",
              "      <td>0.359925</td>\n",
              "      <td>-0.873016</td>\n",
              "      <td>0.141046</td>\n",
              "      <td>-0.459858</td>\n",
              "      <td>-0.790742</td>\n",
              "      <td>-0.382941</td>\n",
              "      <td>-0.352315</td>\n",
              "      <td>-0.261177</td>\n",
              "      <td>-0.500621</td>\n",
              "      <td>-0.901947</td>\n",
              "      <td>-0.382941</td>\n",
              "      <td>-0.747985</td>\n",
              "      <td>-0.391830</td>\n",
              "      <td>0.614840</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.187344</td>\n",
              "      <td>-0.476318</td>\n",
              "      <td>-0.802189</td>\n",
              "      <td>-0.601748</td>\n",
              "      <td>-0.691376</td>\n",
              "      <td>-0.648107</td>\n",
              "      <td>-0.723129</td>\n",
              "      <td>-0.549007</td>\n",
              "      <td>-0.601748</td>\n",
              "      <td>-0.929556</td>\n",
              "      <td>-0.586202</td>\n",
              "      <td>0.320269</td>\n",
              "      <td>-0.873016</td>\n",
              "      <td>0.230617</td>\n",
              "      <td>-0.285643</td>\n",
              "      <td>-0.649094</td>\n",
              "      <td>0.079392</td>\n",
              "      <td>-0.892303</td>\n",
              "      <td>0.939023</td>\n",
              "      <td>-0.067309</td>\n",
              "      <td>-0.779321</td>\n",
              "      <td>0.248037</td>\n",
              "      <td>0.046806</td>\n",
              "      <td>5</td>\n",
              "      <td>WALKING_UPSTAIRS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>0.280262</td>\n",
              "      <td>-0.018698</td>\n",
              "      <td>-0.109685</td>\n",
              "      <td>-0.996123</td>\n",
              "      <td>-0.998074</td>\n",
              "      <td>-0.991967</td>\n",
              "      <td>-0.996509</td>\n",
              "      <td>-0.997516</td>\n",
              "      <td>-0.992607</td>\n",
              "      <td>-0.939714</td>\n",
              "      <td>-0.577026</td>\n",
              "      <td>-0.823482</td>\n",
              "      <td>0.851158</td>\n",
              "      <td>0.693643</td>\n",
              "      <td>0.840339</td>\n",
              "      <td>-0.997394</td>\n",
              "      <td>-0.999975</td>\n",
              "      <td>-0.999988</td>\n",
              "      <td>-0.999860</td>\n",
              "      <td>-0.997109</td>\n",
              "      <td>-0.996239</td>\n",
              "      <td>-0.991663</td>\n",
              "      <td>-0.598011</td>\n",
              "      <td>-0.859599</td>\n",
              "      <td>-0.646639</td>\n",
              "      <td>0.385923</td>\n",
              "      <td>-0.241664</td>\n",
              "      <td>0.101185</td>\n",
              "      <td>0.190957</td>\n",
              "      <td>0.456281</td>\n",
              "      <td>-0.245810</td>\n",
              "      <td>0.311339</td>\n",
              "      <td>0.076550</td>\n",
              "      <td>0.424887</td>\n",
              "      <td>-0.179671</td>\n",
              "      <td>0.156384</td>\n",
              "      <td>-0.052179</td>\n",
              "      <td>-0.163751</td>\n",
              "      <td>0.216597</td>\n",
              "      <td>0.164204</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.684056</td>\n",
              "      <td>-0.747146</td>\n",
              "      <td>-0.949970</td>\n",
              "      <td>-0.996580</td>\n",
              "      <td>-0.997279</td>\n",
              "      <td>-0.997024</td>\n",
              "      <td>-0.997008</td>\n",
              "      <td>-0.997412</td>\n",
              "      <td>-0.996580</td>\n",
              "      <td>-0.999983</td>\n",
              "      <td>-0.996494</td>\n",
              "      <td>-0.956057</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.418893</td>\n",
              "      <td>-0.588401</td>\n",
              "      <td>-0.821342</td>\n",
              "      <td>-0.998563</td>\n",
              "      <td>-0.998383</td>\n",
              "      <td>-0.998003</td>\n",
              "      <td>-0.999262</td>\n",
              "      <td>-0.996855</td>\n",
              "      <td>-0.998563</td>\n",
              "      <td>-0.999995</td>\n",
              "      <td>-0.998056</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.428571</td>\n",
              "      <td>0.534796</td>\n",
              "      <td>-0.750003</td>\n",
              "      <td>-0.961720</td>\n",
              "      <td>0.740652</td>\n",
              "      <td>-0.003130</td>\n",
              "      <td>-0.288663</td>\n",
              "      <td>0.011929</td>\n",
              "      <td>0.768231</td>\n",
              "      <td>-0.467455</td>\n",
              "      <td>-0.519331</td>\n",
              "      <td>2</td>\n",
              "      <td>LAYING</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 563 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      tBodyAcc-mean()-X  tBodyAcc-mean()-Y  ...  subject          Activity\n",
              "2117           0.274369          -0.016706  ...       11            LAYING\n",
              "2937           0.260018          -0.008491  ...       16           SITTING\n",
              "6867           0.278964          -0.016177  ...       29            LAYING\n",
              "983            0.183580          -0.127213  ...        5  WALKING_UPSTAIRS\n",
              "61             0.280262          -0.018698  ...        2            LAYING\n",
              "\n",
              "[5 rows x 563 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq8WKe0x7SZc"
      },
      "source": [
        "## Preparando os Dados para os Modelos\n",
        "\n",
        "*   **x** = Todos os conjuntos de dados tirando as duas ultimas colunas.\n",
        "*   **y** = Ultima coluna, coluna que define a atividade.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTcaNixfDRD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d75aed7b-d4bb-48cf-d3fb-f12457e7ceda"
      },
      "source": [
        "# Separando os os dados do target\n",
        "x_train, y_train = train.iloc[:, :-2], train.iloc[:, -1:]\n",
        "x_validate, y_validate = validate.iloc[:, :-2], validate.iloc[:, -1:]\n",
        "x_test, y_test = test.iloc[:, :-2], test.iloc[:, -1:]\n",
        "print(f'Train: {x_train.shape}, {y_train.shape}\\nValidation: {x_validate.shape}, {y_validate.shape}\\nTraining: {x_test.shape}, {y_test.shape}\\n')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (5149, 561), (5149, 1)\n",
            "Validation: (2575, 561), (2575, 1)\n",
            "Training: (2575, 561), (2575, 1)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPRbqoCVMZfd"
      },
      "source": [
        "Os modelos aceitam apenas números, então foi necessário alterar as strings que definem as classes para números."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_78axvFL4V_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a896440-df63-4c8a-c915-9eaf1c329dad"
      },
      "source": [
        "# Trasformando as strings do target em números\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_validate = le.fit_transform(y_validate)\n",
        "y_test = le.fit_transform(y_test)\n",
        "\n",
        "# --------------Não sei oq é isso\n",
        "scaling_data = MinMaxScaler()\n",
        "x_train = scaling_data.fit_transform(x_train)\n",
        "x_validate = scaling_data.fit_transform(x_validate)\n",
        "x_test = scaling_data.transform(x_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km4Cf8Uj_i-k",
        "outputId": "d5f7e868-53ae-4f55-c5d8-9b5b8614f144"
      },
      "source": [
        "# Separando casos de teste do tipo LAYING\n",
        "test_laying = test[test.Activity == 'LAYING']\n",
        "x_test_laying, y_test_laying = test_laying.iloc[:, :-2], test_laying.iloc[:, -1:]\n",
        "y_test_laying = le.fit_transform(y_test_laying)\n",
        "x_test_laying = scaling_data.fit_transform(x_test_laying)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6waF_f25De4J"
      },
      "source": [
        "# Multi-Layer Perceptron (MLP)\n",
        "\n",
        "Perceptron é utilizado para classificação binária, possuindo apenas 1 neurônio, sendo assim, não podendo se aplicar a dados não lineares. \n",
        "O MLP foi desenvolvido para suprir com essa limitação.Ele possui camadas de entrada e saída e uma ou mais camadas ocultas com muitos neurônios juntos. E enquanto no Perceptron o neurônio deve ter uma função de ativação que impõe um limite, como ReLU ou sigmoid, os neurônios em um MLP podem usar qualquer função de ativação arbitrária.\n",
        "\n",
        "Funções de ativação: \n",
        "*   **ReLU**: Função não linear que a não ativa todos os neurônios ao mesmo tempo. Se a entrada for negativa, ela será convertida em zero e o neurônio não será ativado. Isso significa que, ao mesmo tempo, apenas alguns neurônios são ativados, tornando a rede esparsa e eficiente e fácil para a computação.\n",
        "*   **Softmax**: Alternativa para função sigmóide para lidar com problemas de classificação, já que a mesma é capaz de lidar com mais de 2 classes, diferente da sigmóide.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmF9XuyDG6dz"
      },
      "source": [
        "# Criando o model\n",
        "model_mlp = Sequential()\n",
        "model_mlp.add(Dense(64, activation='relu', input_dim=x_train.shape[1])) # Layer 1\n",
        "model_mlp.add(Dropout(0.5))\n",
        "model_mlp.add(Dense(64, activation='relu')) # Layer 2\n",
        "model_mlp.add(Dropout(0.5))\n",
        "model_mlp.add(Dense(6, activation='softmax')) # Layer 3"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RosQCW8jXvQ-"
      },
      "source": [
        "\n",
        "\n",
        "*   **Compilação, Treino e validação**: O processo de treino foi composto por 20 epocas e 50% do dataset e a validação por 25% do dataset. \n",
        ">* Optimizer: [**Adam**](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) é um algoritmo de otimização que pode ser usado em vez do procedimento clássico de *Stochastic Gradient Descent* (mantém uma única taxa de aprendizado para todas as atualizações de peso e a taxa de aprendizado não muda durante o treinamento) para atualizar os pesos da rede iterativos com base nos dados de treinamento.\n",
        ">* Loss: [sparse_categorical_crossentropy](https://vitalflux.com/keras-categorical-cross-entropy-loss-function/) Usado para modelos de classificação multi-classes quando a output label  sao valores inteiros (0, 1, 2,..).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKw4bSSOXu1h",
        "outputId": "e6aae631-64c2-4117-9eaf-f3c3bda56fb8"
      },
      "source": [
        "# Compilando o model e treinando\n",
        "model_mlp.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy', \n",
        "                                                                                     keras_metrics.sparse_categorical_precision(), \n",
        "                                                                                     keras_metrics.sparse_categorical_recall(), \n",
        "                                                                                     keras_metrics.sparse_categorical_f1_score(), \n",
        "                                                                                     keras_metrics.sparse_categorical_true_negative()]) # optimizer 'adam'\n",
        "history = model_mlp.fit(x_train, y_train, batch_size=64, epochs=20, validation_data=(x_validate, y_validate)) # teinando e validando "
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_metrics/metrics.py:26: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  return object.__getattribute__(self, name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81/81 [==============================] - 2s 9ms/step - loss: 0.1218 - accuracy: 0.9514 - precision: 0.9967 - recall: 0.9815 - f1_score: 0.9890 - true_negative: 2121.1482 - val_loss: 0.0775 - val_accuracy: 0.9786 - val_precision: 0.9973 - val_recall: 0.9886 - val_f1_score: 0.9929 - val_true_negative: 5249.4878\n",
            "Epoch 2/20\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1023 - accuracy: 0.9606 - precision: 0.9951 - recall: 0.9905 - f1_score: 0.9928 - true_negative: 8361.5557 - val_loss: 0.0965 - val_accuracy: 0.9740 - val_precision: 0.9947 - val_recall: 0.9922 - val_f1_score: 0.9935 - val_true_negative: 11494.4883\n",
            "Epoch 3/20\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1140 - accuracy: 0.9542 - precision: 0.9948 - recall: 0.9910 - f1_score: 0.9929 - true_negative: 14608.6045 - val_loss: 0.0926 - val_accuracy: 0.9748 - val_precision: 0.9951 - val_recall: 0.9906 - val_f1_score: 0.9929 - val_true_negative: 17744.4883\n",
            "Epoch 4/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1275 - accuracy: 0.9464 - precision: 0.9950 - recall: 0.9906 - f1_score: 0.9928 - true_negative: 20851.6660 - val_loss: 0.1922 - val_accuracy: 0.9592 - val_precision: 0.9948 - val_recall: 0.9904 - val_f1_score: 0.9926 - val_true_negative: 23991.4883\n",
            "Epoch 5/20\n",
            "81/81 [==============================] - 1s 6ms/step - loss: 0.1304 - accuracy: 0.9466 - precision: 0.9948 - recall: 0.9906 - f1_score: 0.9927 - true_negative: 27092.0000 - val_loss: 0.1120 - val_accuracy: 0.9697 - val_precision: 0.9950 - val_recall: 0.9909 - val_f1_score: 0.9929 - val_true_negative: 30241.4883\n",
            "Epoch 6/20\n",
            "81/81 [==============================] - 0s 6ms/step - loss: 0.1069 - accuracy: 0.9569 - precision: 0.9950 - recall: 0.9912 - f1_score: 0.9931 - true_negative: 33353.9375 - val_loss: 0.0860 - val_accuracy: 0.9790 - val_precision: 0.9953 - val_recall: 0.9913 - val_f1_score: 0.9933 - val_true_negative: 36492.4883\n",
            "Epoch 7/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1156 - accuracy: 0.9524 - precision: 0.9953 - recall: 0.9913 - f1_score: 0.9933 - true_negative: 39611.7539 - val_loss: 0.0836 - val_accuracy: 0.9763 - val_precision: 0.9955 - val_recall: 0.9912 - val_f1_score: 0.9933 - val_true_negative: 42743.4883\n",
            "Epoch 8/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1186 - accuracy: 0.9495 - precision: 0.9955 - recall: 0.9913 - f1_score: 0.9934 - true_negative: 45849.5430 - val_loss: 0.0938 - val_accuracy: 0.9732 - val_precision: 0.9956 - val_recall: 0.9911 - val_f1_score: 0.9934 - val_true_negative: 48994.4883\n",
            "Epoch 9/20\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1108 - accuracy: 0.9567 - precision: 0.9956 - recall: 0.9912 - f1_score: 0.9934 - true_negative: 52099.3086 - val_loss: 0.0917 - val_accuracy: 0.9755 - val_precision: 0.9958 - val_recall: 0.9910 - val_f1_score: 0.9934 - val_true_negative: 55246.4883\n",
            "Epoch 10/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1083 - accuracy: 0.9540 - precision: 0.9958 - recall: 0.9911 - f1_score: 0.9934 - true_negative: 58356.7148 - val_loss: 0.1016 - val_accuracy: 0.9748 - val_precision: 0.9959 - val_recall: 0.9910 - val_f1_score: 0.9935 - val_true_negative: 61498.4375\n",
            "Epoch 11/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1087 - accuracy: 0.9551 - precision: 0.9957 - recall: 0.9911 - f1_score: 0.9934 - true_negative: 64609.3086 - val_loss: 0.0983 - val_accuracy: 0.9709 - val_precision: 0.9957 - val_recall: 0.9912 - val_f1_score: 0.9934 - val_true_negative: 67744.4844\n",
            "Epoch 12/20\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1307 - accuracy: 0.9470 - precision: 0.9957 - recall: 0.9913 - f1_score: 0.9935 - true_negative: 70866.2344 - val_loss: 0.0850 - val_accuracy: 0.9744 - val_precision: 0.9956 - val_recall: 0.9913 - val_f1_score: 0.9934 - val_true_negative: 73993.4844\n",
            "Epoch 13/20\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1102 - accuracy: 0.9540 - precision: 0.9956 - recall: 0.9913 - f1_score: 0.9934 - true_negative: 77097.5078 - val_loss: 0.0797 - val_accuracy: 0.9786 - val_precision: 0.9957 - val_recall: 0.9914 - val_f1_score: 0.9935 - val_true_negative: 80243.4844\n",
            "Epoch 14/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1128 - accuracy: 0.9526 - precision: 0.9957 - recall: 0.9913 - f1_score: 0.9935 - true_negative: 83356.8125 - val_loss: 0.0880 - val_accuracy: 0.9783 - val_precision: 0.9957 - val_recall: 0.9912 - val_f1_score: 0.9935 - val_true_negative: 86493.4375\n",
            "Epoch 15/20\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1128 - accuracy: 0.9542 - precision: 0.9955 - recall: 0.9910 - f1_score: 0.9933 - true_negative: 89608.4844 - val_loss: 0.0924 - val_accuracy: 0.9717 - val_precision: 0.9956 - val_recall: 0.9909 - val_f1_score: 0.9932 - val_true_negative: 92740.4375\n",
            "Epoch 16/20\n",
            "81/81 [==============================] - 0s 6ms/step - loss: 0.1224 - accuracy: 0.9474 - precision: 0.9955 - recall: 0.9909 - f1_score: 0.9932 - true_negative: 95841.5156 - val_loss: 0.0688 - val_accuracy: 0.9779 - val_precision: 0.9955 - val_recall: 0.9908 - val_f1_score: 0.9931 - val_true_negative: 98988.5625\n",
            "Epoch 17/20\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1135 - accuracy: 0.9561 - precision: 0.9954 - recall: 0.9908 - f1_score: 0.9931 - true_negative: 102092.0000 - val_loss: 0.0920 - val_accuracy: 0.9755 - val_precision: 0.9954 - val_recall: 0.9906 - val_f1_score: 0.9930 - val_true_negative: 105235.4844\n",
            "Epoch 18/20\n",
            "81/81 [==============================] - 0s 6ms/step - loss: 0.1142 - accuracy: 0.9518 - precision: 0.9952 - recall: 0.9907 - f1_score: 0.9929 - true_negative: 108340.5938 - val_loss: 0.0835 - val_accuracy: 0.9748 - val_precision: 0.9952 - val_recall: 0.9905 - val_f1_score: 0.9929 - val_true_negative: 111480.4844\n",
            "Epoch 19/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1178 - accuracy: 0.9513 - precision: 0.9952 - recall: 0.9905 - f1_score: 0.9929 - true_negative: 114597.0703 - val_loss: 0.0887 - val_accuracy: 0.9755 - val_precision: 0.9953 - val_recall: 0.9905 - val_f1_score: 0.9929 - val_true_negative: 117731.4844\n",
            "Epoch 20/20\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1130 - accuracy: 0.9555 - precision: 0.9952 - recall: 0.9905 - f1_score: 0.9929 - true_negative: 120822.9766 - val_loss: 0.0768 - val_accuracy: 0.9783 - val_precision: 0.9953 - val_recall: 0.9905 - val_f1_score: 0.9929 - val_true_negative: 123979.4844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS_simmq8A4M"
      },
      "source": [
        "Testando o modelo com dataset de teste que equivale 50% do dataset total"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCqSvo7hjXl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69facbdc-b7dd-4f1d-fb91-f25328b1e199"
      },
      "source": [
        "# Testa o treino com todas as classes\n",
        "test_results = model_mlp.evaluate(x_test, y_test, verbose=1)\n",
        "print(f'Loss: {test_results[0]}\\nAccuracy: {test_results[1]}\\nPrecision: {test_results[2]}\\nRecall: {test_results[3]}\\nF1 Score: {test_results[1]}\\nSpecificity: {test_results[1]}')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.9755 - precision: 0.9955 - recall: 0.9911 - f1_score: 0.9933 - true_negative: 132354.3125\n",
            "Loss: 0.08334586024284363\n",
            "Accuracy: 0.9755339622497559\n",
            "Precision: 0.9954994320869446\n",
            "Recall: 0.9910711646080017\n",
            "F1 Score: 0.9755339622497559\n",
            "Specificity: 0.9755339622497559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ERqhIRbBBuq",
        "outputId": "dd3e9f08-d3cd-462d-ab6e-f0a3b35f4abc"
      },
      "source": [
        "# Testa o treino apenas com a classe LAYING\n",
        "test_results = model_mlp.evaluate(x_test_laying, y_test_laying, verbose=1)\n",
        "print(f'Loss: {test_results[0]}\\nAccuracy: {test_results[1]}\\nPrecision: {test_results[2]}\\nRecall: {test_results[3]}\\nF1 Score: {test_results[1]}\\nSpecificity: {test_results[1]}')"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 1.2709 - accuracy: 0.8697 - precision: 0.9956 - recall: 0.9902 - f1_score: 0.9929 - true_negative: 133377.0000\n",
            "Loss: 1.270925521850586\n",
            "Accuracy: 0.8697478771209717\n",
            "Precision: 0.9955660700798035\n",
            "Recall: 0.9901862740516663\n",
            "F1 Score: 0.8697478771209717\n",
            "Specificity: 0.8697478771209717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJRL8rJmkJaU"
      },
      "source": [
        "# Convolutional Neural Network (CNN)\n",
        "Uma **Artificial Neural Network (ANN)** é uma série de algoritmos que se esforçam para reconhecer relacionamentos subjacentes em um conjunto de dados, por meio de um processo que imita a maneira como o cérebro humano opera. As **ANN** podem se adaptar a mudanças de entrada para que a rede gere o melhor resultado possível sem a necessidade de redesenhar os critérios de saída.\n",
        "\n",
        "As **Convolutional Neural Network (CNN)** são um tipo especializado de ANN que usam convolução no lugar da multiplicação geral da matriz em pelo menos uma de suas camadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yD15rTtkP3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c255bde-88c5-46d8-c3e1-3b7e01eef720"
      },
      "source": [
        "n_timesteps, n_features, n_outputs = x_train.shape[0], x_train.shape[1], y_train.shape[0]\n",
        "\n",
        "# Adicionando mais uma dimensão a x, para ficarem 3, como é pedido no Conv1D\n",
        "x_train_cnn = x_train[..., None]\n",
        "x_validate_cnn = x_validate[..., None]\n",
        "\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=x_train_cnn.shape[1:]))\n",
        "model_cnn.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
        "model_cnn.add(Dropout(0.5))\n",
        "model_cnn.add(MaxPooling1D(pool_size=2))\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy',\n",
        "                                                                                     keras_metrics.sparse_categorical_precision(), \n",
        "                                                                                     keras_metrics.sparse_categorical_recall(), \n",
        "                                                                                     keras_metrics.sparse_categorical_f1_score(), \n",
        "                                                                                     keras_metrics.sparse_categorical_true_negative()])\n",
        "history = model_cnn.fit(x_train_cnn, y_train, batch_size=64, epochs=20, validation_data=(x_validate_cnn, y_validate))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_metrics/metrics.py:26: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  return object.__getattribute__(self, name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81/81 [==============================] - 12s 137ms/step - loss: 0.7435 - accuracy: 0.6992 - precision: 0.7364 - recall: 0.3092 - f1_score: 0.4159 - true_negative: 2099.5432 - val_loss: 0.3141 - val_accuracy: 0.8983 - val_precision: 0.9850 - val_recall: 0.7007 - val_f1_score: 0.8185 - val_true_negative: 5239.6343\n",
            "Epoch 2/20\n",
            "81/81 [==============================] - 11s 136ms/step - loss: 0.2169 - accuracy: 0.9114 - precision: 0.9859 - recall: 0.8068 - f1_score: 0.8871 - true_negative: 8340.7656 - val_loss: 0.1906 - val_accuracy: 0.9348 - val_precision: 0.9885 - val_recall: 0.8602 - val_f1_score: 0.9199 - val_true_negative: 11481.6338\n",
            "Epoch 3/20\n",
            "81/81 [==============================] - 11s 133ms/step - loss: 0.1482 - accuracy: 0.9425 - precision: 0.9888 - recall: 0.8893 - f1_score: 0.9364 - true_negative: 14592.0615 - val_loss: 0.1483 - val_accuracy: 0.9487 - val_precision: 0.9903 - val_recall: 0.9086 - val_f1_score: 0.9476 - val_true_negative: 17727.5117\n",
            "Epoch 4/20\n",
            "81/81 [==============================] - 11s 135ms/step - loss: 0.1263 - accuracy: 0.9474 - precision: 0.9913 - recall: 0.9220 - f1_score: 0.9554 - true_negative: 20838.2598 - val_loss: 0.1437 - val_accuracy: 0.9495 - val_precision: 0.9924 - val_recall: 0.9320 - val_f1_score: 0.9613 - val_true_negative: 23980.7812\n",
            "Epoch 5/20\n",
            "81/81 [==============================] - 11s 136ms/step - loss: 0.0959 - accuracy: 0.9629 - precision: 0.9932 - recall: 0.9396 - f1_score: 0.9657 - true_negative: 27106.2344 - val_loss: 0.1071 - val_accuracy: 0.9623 - val_precision: 0.9939 - val_recall: 0.9460 - val_f1_score: 0.9693 - val_true_negative: 30235.4395\n",
            "Epoch 6/20\n",
            "81/81 [==============================] - 11s 134ms/step - loss: 0.0838 - accuracy: 0.9650 - precision: 0.9941 - recall: 0.9510 - f1_score: 0.9721 - true_negative: 33354.8750 - val_loss: 0.1065 - val_accuracy: 0.9592 - val_precision: 0.9946 - val_recall: 0.9551 - val_f1_score: 0.9744 - val_true_negative: 36488.2188\n",
            "Epoch 7/20\n",
            "81/81 [==============================] - 11s 140ms/step - loss: 0.0893 - accuracy: 0.9643 - precision: 0.9948 - recall: 0.9585 - f1_score: 0.9763 - true_negative: 39610.0742 - val_loss: 0.1138 - val_accuracy: 0.9577 - val_precision: 0.9952 - val_recall: 0.9616 - val_f1_score: 0.9781 - val_true_negative: 42741.7812\n",
            "Epoch 8/20\n",
            "81/81 [==============================] - 11s 131ms/step - loss: 0.0745 - accuracy: 0.9730 - precision: 0.9954 - recall: 0.9642 - f1_score: 0.9795 - true_negative: 45858.4062 - val_loss: 0.0932 - val_accuracy: 0.9709 - val_precision: 0.9957 - val_recall: 0.9665 - val_f1_score: 0.9809 - val_true_negative: 48996.7812\n",
            "Epoch 9/20\n",
            "81/81 [==============================] - 11s 136ms/step - loss: 0.0635 - accuracy: 0.9757 - precision: 0.9958 - recall: 0.9685 - f1_score: 0.9820 - true_negative: 52101.3320 - val_loss: 0.0929 - val_accuracy: 0.9693 - val_precision: 0.9960 - val_recall: 0.9702 - val_f1_score: 0.9829 - val_true_negative: 55250.8281\n",
            "Epoch 10/20\n",
            "81/81 [==============================] - 11s 131ms/step - loss: 0.0659 - accuracy: 0.9728 - precision: 0.9963 - recall: 0.9717 - f1_score: 0.9838 - true_negative: 58372.4570 - val_loss: 0.0984 - val_accuracy: 0.9658 - val_precision: 0.9964 - val_recall: 0.9731 - val_f1_score: 0.9847 - val_true_negative: 61506.4883\n",
            "Epoch 11/20\n",
            "81/81 [==============================] - 11s 131ms/step - loss: 0.0496 - accuracy: 0.9823 - precision: 0.9965 - recall: 0.9744 - f1_score: 0.9853 - true_negative: 64623.3945 - val_loss: 0.1194 - val_accuracy: 0.9581 - val_precision: 0.9966 - val_recall: 0.9756 - val_f1_score: 0.9860 - val_true_negative: 67760.4844\n",
            "Epoch 12/20\n",
            "81/81 [==============================] - 11s 131ms/step - loss: 0.0687 - accuracy: 0.9773 - precision: 0.9967 - recall: 0.9767 - f1_score: 0.9866 - true_negative: 70866.9766 - val_loss: 0.0824 - val_accuracy: 0.9744 - val_precision: 0.9968 - val_recall: 0.9776 - val_f1_score: 0.9871 - val_true_negative: 74014.4375\n",
            "Epoch 13/20\n",
            "81/81 [==============================] - 11s 134ms/step - loss: 0.0594 - accuracy: 0.9802 - precision: 0.9968 - recall: 0.9785 - f1_score: 0.9876 - true_negative: 77122.2734 - val_loss: 0.0861 - val_accuracy: 0.9728 - val_precision: 0.9969 - val_recall: 0.9794 - val_f1_score: 0.9881 - val_true_negative: 80267.8281\n",
            "Epoch 14/20\n",
            "81/81 [==============================] - 11s 132ms/step - loss: 0.0570 - accuracy: 0.9788 - precision: 0.9970 - recall: 0.9801 - f1_score: 0.9885 - true_negative: 83390.6797 - val_loss: 0.0982 - val_accuracy: 0.9670 - val_precision: 0.9971 - val_recall: 0.9808 - val_f1_score: 0.9889 - val_true_negative: 86523.8281\n",
            "Epoch 15/20\n",
            "81/81 [==============================] - 11s 133ms/step - loss: 0.0548 - accuracy: 0.9796 - precision: 0.9972 - recall: 0.9815 - f1_score: 0.9893 - true_negative: 89656.1328 - val_loss: 0.0891 - val_accuracy: 0.9697 - val_precision: 0.9973 - val_recall: 0.9821 - val_f1_score: 0.9897 - val_true_negative: 92779.8281\n",
            "Epoch 16/20\n",
            "81/81 [==============================] - 11s 133ms/step - loss: 0.0432 - accuracy: 0.9839 - precision: 0.9974 - recall: 0.9827 - f1_score: 0.9900 - true_negative: 95889.6797 - val_loss: 0.1023 - val_accuracy: 0.9670 - val_precision: 0.9975 - val_recall: 0.9832 - val_f1_score: 0.9903 - val_true_negative: 99035.4844\n",
            "Epoch 17/20\n",
            "81/81 [==============================] - 11s 132ms/step - loss: 0.0454 - accuracy: 0.9847 - precision: 0.9975 - recall: 0.9838 - f1_score: 0.9906 - true_negative: 102140.4297 - val_loss: 0.0892 - val_accuracy: 0.9697 - val_precision: 0.9976 - val_recall: 0.9842 - val_f1_score: 0.9909 - val_true_negative: 105289.8281\n",
            "Epoch 18/20\n",
            "81/81 [==============================] - 11s 134ms/step - loss: 0.0392 - accuracy: 0.9874 - precision: 0.9977 - recall: 0.9847 - f1_score: 0.9911 - true_negative: 108399.6328 - val_loss: 0.0750 - val_accuracy: 0.9755 - val_precision: 0.9977 - val_recall: 0.9851 - val_f1_score: 0.9914 - val_true_negative: 111545.8281\n",
            "Epoch 19/20\n",
            "81/81 [==============================] - 11s 135ms/step - loss: 0.0442 - accuracy: 0.9833 - precision: 0.9978 - recall: 0.9855 - f1_score: 0.9916 - true_negative: 114660.5078 - val_loss: 0.1013 - val_accuracy: 0.9666 - val_precision: 0.9978 - val_recall: 0.9859 - val_f1_score: 0.9918 - val_true_negative: 117801.4844\n",
            "Epoch 20/20\n",
            "81/81 [==============================] - 11s 134ms/step - loss: 0.0460 - accuracy: 0.9829 - precision: 0.9978 - recall: 0.9862 - f1_score: 0.9920 - true_negative: 120912.5469 - val_loss: 0.0920 - val_accuracy: 0.9720 - val_precision: 0.9979 - val_recall: 0.9866 - val_f1_score: 0.9922 - val_true_negative: 124055.7812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpZqaAIrt1pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a88052d-c266-406d-fef0-1c404ca148f7"
      },
      "source": [
        "# Testando o model após treinamento\n",
        "x_test_cnn = x_test[..., None]\n",
        "test_results = model_cnn.evaluate(x_test, y_test, verbose=1)\n",
        "print(f'Loss: {test_results[0]}\\nAccuracy: {test_results[1]}\\nPrecision: {test_results[2]}\\nRecall: {test_results[3]}\\nF1 Score: {test_results[1]}\\nSpecificity: {test_results[1]}')"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_metrics/metrics.py:26: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  return object.__getattribute__(self, name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81/81 [==============================] - 2s 16ms/step - loss: 0.0784 - accuracy: 0.9670 - precision: 0.9979 - recall: 0.9868 - f1_score: 0.9923 - true_negative: 126133.4531\n",
            "Loss: 0.07840050011873245\n",
            "Accuracy: 0.9669902920722961\n",
            "Precision: 0.9978524446487427\n",
            "Recall: 0.9867883324623108\n",
            "F1 Score: 0.9669902920722961\n",
            "Specificity: 0.9669902920722961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exw1CpM3pfcg",
        "outputId": "2c8a2845-5b75-4d93-fc46-4dff7a98f077",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Testa o treino apenas com a classe LAYING\n",
        "test_results = model_cnn.evaluate(x_test_laying, y_test_laying, verbose=1)\n",
        "print(f'Loss: {test_results[0]}\\nAccuracy: {test_results[1]}\\nPrecision: {test_results[2]}\\nRecall: {test_results[3]}\\nF1 Score: {test_results[1]}\\nSpecificity: {test_results[1]}')"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 18ms/step - loss: 0.4492 - accuracy: 0.8676 - precision: 0.9979 - recall: 0.9859 - f1_score: 0.9919 - true_negative: 127156.0000\n",
            "Loss: 0.44915956258773804\n",
            "Accuracy: 0.8676470518112183\n",
            "Precision: 0.9978809356689453\n",
            "Recall: 0.9859211444854736\n",
            "F1 Score: 0.8676470518112183\n",
            "Specificity: 0.8676470518112183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcBUtkdcBNfY"
      },
      "source": [
        "# Recurrent Neural Network (RNN)\n",
        "\n",
        "**Recurrent Neural Network (RNN)** tem uma conexão recorrente no *hidden state*. Essa restrição de loop garante que as informações sequenciais sejam capturadas nos dados de entrada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJpQMVqfPWlw",
        "outputId": "33fdbc8b-d7ba-4fe5-febc-265714daab7d"
      },
      "source": [
        "x_train_rnn = x_train[..., None]\n",
        "x_validate_rnn = x_validate[..., None]\n",
        "\n",
        "model_rnn2 = keras.models.Sequential()\n",
        "model_rnn2.add(keras.Input(shape=x_train_rnn.shape[1:])) \n",
        "model_rnn2.add(layers.SimpleRNN(128, return_sequences=True, activation='relu'))\n",
        "model_rnn2.add(Flatten())\n",
        "model_rnn2.add(layers.Dense(10))\n",
        "\n",
        "model_rnn2.summary()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 561, 128)          16640     \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 71808)             0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                718090    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 734,730\n",
            "Trainable params: 734,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m13sO2U6Jn74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc8ab6e-00d5-4010-a87c-3cfc9a6f7fe0"
      },
      "source": [
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optim = keras.optimizers.Adam(lr=0.001)\n",
        "metrics = [\"accuracy\", \n",
        "            keras_metrics.sparse_categorical_precision(), \n",
        "            keras_metrics.sparse_categorical_recall(), \n",
        "            keras_metrics.sparse_categorical_f1_score(), \n",
        "            keras_metrics.sparse_categorical_true_negative()]\n",
        "\n",
        "model_rnn2.compile(loss=loss, optimizer=optim, metrics=metrics)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tav3miXhJuYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43726f51-05d1-4703-add1-e79affb166bf"
      },
      "source": [
        "model_rnn2.fit(\n",
        "    x_train_rnn, y_train, validation_data=(x_validate_rnn, y_validate), batch_size=64, epochs=10\n",
        ")"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_metrics/metrics.py:26: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  return object.__getattribute__(self, name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81/81 [==============================] - 25s 293ms/step - loss: 0.4316 - accuracy: 0.8167 - precision: 1.0557 - recall: 6.8735 - f1_score: 1.8087 - true_negative: 2986.3333 - val_loss: 0.1790 - val_accuracy: 0.9239 - val_precision: 2.7973 - val_recall: 10.4980 - val_f1_score: 4.4133 - val_true_negative: 13659.6094\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 22s 275ms/step - loss: 0.1167 - accuracy: 0.9528 - precision: 5.9735 - recall: 11.6948 - f1_score: 7.7328 - true_negative: 27463.0859 - val_loss: 0.1884 - val_accuracy: 0.9336 - val_precision: -684.0177 - val_recall: 12.2312 - val_f1_score: 25.4572 - val_true_negative: 44093.3398\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 23s 289ms/step - loss: 0.0797 - accuracy: 0.9728 - precision: -12.8158 - recall: 12.7323 - f1_score: -793.9396 - true_negative: 62099.2344 - val_loss: 0.1009 - val_accuracy: 0.9608 - val_precision: -8.3399 - val_recall: 13.1102 - val_f1_score: -47.2496 - val_true_negative: 79114.2891\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 23s 281ms/step - loss: 0.0578 - accuracy: 0.9806 - precision: -6.3351 - recall: 13.3705 - f1_score: -24.8157 - true_negative: 97270.4922 - val_loss: 0.3647 - val_accuracy: 0.8932 - val_precision: -4.8497 - val_recall: 13.8012 - val_f1_score: -15.0069 - val_true_negative: 118055.2188\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 23s 279ms/step - loss: 0.0712 - accuracy: 0.9763 - precision: -4.6697 - recall: 14.1552 - f1_score: -13.9592 - true_negative: 137013.7031 - val_loss: 0.1026 - val_accuracy: 0.9631 - val_precision: -3.8420 - val_recall: 14.3531 - val_f1_score: -10.5331 - val_true_negative: 159149.9531\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 23s 281ms/step - loss: 0.0486 - accuracy: 0.9833 - precision: -2.9089 - recall: 14.3553 - f1_score: -7.3056 - true_negative: 184982.4531 - val_loss: 0.0882 - val_accuracy: 0.9697 - val_precision: -2.5878 - val_recall: 14.6552 - val_f1_score: -6.2861 - val_true_negative: 210877.6562\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 22s 273ms/step - loss: 0.0353 - accuracy: 0.9880 - precision: -2.4399 - recall: 15.0388 - f1_score: -5.8265 - true_negative: 237376.5000 - val_loss: 0.0629 - val_accuracy: 0.9794 - val_precision: -2.3305 - val_recall: 15.3056 - val_f1_score: -5.4983 - val_true_negative: 262577.8750\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 23s 280ms/step - loss: 0.0244 - accuracy: 0.9918 - precision: -2.2834 - recall: 15.6148 - f1_score: -5.3492 - true_negative: 288060.2812 - val_loss: 0.0729 - val_accuracy: 0.9744 - val_precision: -2.2444 - val_recall: 15.9148 - val_f1_score: -5.2258 - val_true_negative: 313983.9375\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 23s 282ms/step - loss: 0.0225 - accuracy: 0.9928 - precision: -2.2025 - recall: 16.2118 - f1_score: -5.0979 - true_negative: 341182.5312 - val_loss: 0.0715 - val_accuracy: 0.9736 - val_precision: -2.1229 - val_recall: 16.4150 - val_f1_score: -4.8766 - val_true_negative: 368831.0625\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 23s 279ms/step - loss: 0.0206 - accuracy: 0.9936 - precision: -2.0625 - recall: 16.5914 - f1_score: -4.7106 - true_negative: 396438.5312 - val_loss: 0.0835 - val_accuracy: 0.9693 - val_precision: -2.0254 - val_recall: 16.8380 - val_f1_score: -4.6049 - val_true_negative: 425040.6875\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8315eea750>"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoBTjecAVhia",
        "outputId": "5852f5de-ace5-4f12-caed-fbe2bd125787"
      },
      "source": [
        "test_results = model_rnn2.evaluate(x_test, y_test, batch_size=64, verbose=2)\n",
        "print(f'Loss: {test_results[0]}\\nAccuracy: {test_results[1]}\\nPrecision: {test_results[2]}\\nRecall: {test_results[3]}\\nF1 Score: {test_results[1]}\\nSpecificity: {test_results[1]}')"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_metrics/metrics.py:26: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  return object.__getattribute__(self, name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 - 4s - loss: 0.0831 - accuracy: 0.9705 - precision: -1.9882e+00 - recall: 16.9973 - f1_score: -4.5031e+00 - true_negative: 444869.4688 - 4s/epoch - 95ms/step\n",
            "Loss: 0.08310163021087646\n",
            "Accuracy: 0.9704854488372803\n",
            "Precision: -1.9881937503814697\n",
            "Recall: 16.99733543395996\n",
            "F1 Score: 0.9704854488372803\n",
            "Specificity: 0.9704854488372803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVUWa6D4q-4Y",
        "outputId": "b263e295-d520-44c8-9069-44495806d778",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Testa o treino apenas com a classe LAYING\n",
        "test_results = model_rnn2.evaluate(x_test_laying, y_test_laying, verbose=1)\n",
        "print(f'Loss: {test_results[0]}\\nAccuracy: {test_results[1]}\\nPrecision: {test_results[2]}\\nRecall: {test_results[3]}\\nF1 Score: {test_results[1]}\\nSpecificity: {test_results[1]}')"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 60ms/step - loss: 0.7791 - accuracy: 0.8130 - precision: -2.0734 - recall: 17.0369 - f1_score: -4.7220 - true_negative: 453908.0000\n",
            "Loss: 0.7790966033935547\n",
            "Accuracy: 0.8130252361297607\n",
            "Precision: -2.0734379291534424\n",
            "Recall: 17.03689193725586\n",
            "F1 Score: 0.8130252361297607\n",
            "Specificity: 0.8130252361297607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEtTk01aGzlo"
      },
      "source": [
        "# Modelo Híbrido\n",
        "Criando modelo híbrido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8UCRcOOG34C",
        "outputId": "3decf75c-ae26-45b0-c909-c51e6f0382f0"
      },
      "source": [
        "x_train = x_train[..., None]\n",
        "x_validate = x_validate[..., None]\n",
        "\n",
        "model_hyb = Sequential()\n",
        "# Model RNN\n",
        "model_hyb.add(keras.Input(shape=x_train_rnn.shape[1:])) \n",
        "model_hyb.add(layers.SimpleRNN(128, return_sequences=True, activation='relu'))\n",
        "# Model CNN\n",
        "model_hyb.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
        "model_hyb.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
        "model_hyb.add(Dropout(0.5))\n",
        "model_hyb.add(MaxPooling1D(pool_size=2))\n",
        "model_hyb.add(Flatten())\n",
        "# Model MLP\n",
        "model_hyb.add(Dense(64, activation='relu')) # Layer 1\n",
        "model_hyb.add(Dropout(0.5))\n",
        "model_hyb.add(Dense(64, activation='relu')) # Layer 2\n",
        "model_hyb.add(Dropout(0.5))\n",
        "model_hyb.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_hyb.summary()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (None, 561, 128)          16640     \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 560, 64)           16448     \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 559, 64)           8256      \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 559, 64)           0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 279, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 17856)             0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 64)                1142848   \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,189,002\n",
            "Trainable params: 1,189,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoXcRTZd-PPG",
        "outputId": "f4f5e4b5-4e53-41d5-b753-289d239e77a6"
      },
      "source": [
        "model_hyb.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy',\n",
        "                                                                                      keras_metrics.sparse_categorical_precision(), \n",
        "                                                                                      keras_metrics.sparse_categorical_recall(), \n",
        "                                                                                      keras_metrics.sparse_categorical_f1_score(), \n",
        "                                                                                      keras_metrics.sparse_categorical_true_negative()])\n",
        "history = model_hyb.fit(x_train, y_train, batch_size=64, epochs=20, validation_data=(x_validate, y_validate))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_metrics/metrics.py:26: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  return object.__getattribute__(self, name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81/81 [==============================] - 41s 485ms/step - loss: 1.5842 - accuracy: 0.3909 - precision: 0.4218 - recall: 0.0807 - f1_score: 0.1291 - true_negative: 2086.2100 - val_loss: 0.6813 - val_accuracy: 0.8462 - val_precision: 0.8509 - val_recall: 0.4114 - val_f1_score: 0.5528 - val_true_negative: 5166.9023\n",
            "Epoch 2/20\n",
            "81/81 [==============================] - 39s 486ms/step - loss: 0.7026 - accuracy: 0.7114 - precision: 0.9063 - recall: 0.5979 - f1_score: 0.7197 - true_negative: 8243.5557 - val_loss: 0.3229 - val_accuracy: 0.8691 - val_precision: 0.9287 - val_recall: 0.6932 - val_f1_score: 0.7938 - val_true_negative: 11365.1953\n",
            "Epoch 3/20\n",
            "81/81 [==============================] - 39s 479ms/step - loss: 0.4930 - accuracy: 0.8033 - precision: 0.9409 - recall: 0.7484 - f1_score: 0.8336 - true_negative: 14462.0244 - val_loss: 0.2388 - val_accuracy: 0.9107 - val_precision: 0.9490 - val_recall: 0.7863 - val_f1_score: 0.8600 - val_true_negative: 17588.8301\n",
            "Epoch 4/20\n",
            "81/81 [==============================] - 38s 475ms/step - loss: 0.3936 - accuracy: 0.8423 - precision: 0.9544 - recall: 0.8104 - f1_score: 0.8765 - true_negative: 20700.1602 - val_loss: 0.2057 - val_accuracy: 0.9266 - val_precision: 0.9590 - val_recall: 0.8304 - val_f1_score: 0.8901 - val_true_negative: 23820.7070\n",
            "Epoch 5/20\n",
            "81/81 [==============================] - 39s 481ms/step - loss: 0.3472 - accuracy: 0.8598 - precision: 0.9626 - recall: 0.8470 - f1_score: 0.9011 - true_negative: 26919.6426 - val_loss: 0.1577 - val_accuracy: 0.9313 - val_precision: 0.9654 - val_recall: 0.8598 - val_f1_score: 0.9096 - val_true_negative: 30057.8301\n",
            "Epoch 6/20\n",
            "81/81 [==============================] - 39s 480ms/step - loss: 0.2919 - accuracy: 0.8825 - precision: 0.9677 - recall: 0.8705 - f1_score: 0.9165 - true_negative: 33163.6914 - val_loss: 0.1432 - val_accuracy: 0.9417 - val_precision: 0.9692 - val_recall: 0.8791 - val_f1_score: 0.9219 - val_true_negative: 36292.8281\n",
            "Epoch 7/20\n",
            "81/81 [==============================] - 39s 480ms/step - loss: 0.2769 - accuracy: 0.9017 - precision: 0.9705 - recall: 0.8866 - f1_score: 0.9267 - true_negative: 39400.9766 - val_loss: 0.1625 - val_accuracy: 0.9425 - val_precision: 0.9720 - val_recall: 0.8926 - val_f1_score: 0.9306 - val_true_negative: 42530.8281\n",
            "Epoch 8/20\n",
            "81/81 [==============================] - 38s 475ms/step - loss: 0.2670 - accuracy: 0.8916 - precision: 0.9731 - recall: 0.8982 - f1_score: 0.9342 - true_negative: 45637.7891 - val_loss: 0.1375 - val_accuracy: 0.9449 - val_precision: 0.9741 - val_recall: 0.9028 - val_f1_score: 0.9371 - val_true_negative: 48768.8281\n",
            "Epoch 9/20\n",
            "81/81 [==============================] - 39s 477ms/step - loss: 0.2388 - accuracy: 0.9118 - precision: 0.9747 - recall: 0.9070 - f1_score: 0.9396 - true_negative: 51865.2109 - val_loss: 0.0905 - val_accuracy: 0.9705 - val_precision: 0.9755 - val_recall: 0.9105 - val_f1_score: 0.9419 - val_true_negative: 55003.7812\n",
            "Epoch 10/20\n",
            "81/81 [==============================] - 39s 485ms/step - loss: 0.2262 - accuracy: 0.9196 - precision: 0.9758 - recall: 0.9136 - f1_score: 0.9437 - true_negative: 58100.2734 - val_loss: 0.1194 - val_accuracy: 0.9518 - val_precision: 0.9762 - val_recall: 0.9165 - val_f1_score: 0.9454 - val_true_negative: 61234.5117\n",
            "Epoch 11/20\n",
            "81/81 [==============================] - 39s 480ms/step - loss: 0.2137 - accuracy: 0.9144 - precision: 0.9770 - recall: 0.9189 - f1_score: 0.9471 - true_negative: 64344.5820 - val_loss: 0.1118 - val_accuracy: 0.9631 - val_precision: 0.9777 - val_recall: 0.9211 - val_f1_score: 0.9485 - val_true_negative: 67477.8281\n",
            "Epoch 12/20\n",
            "81/81 [==============================] - 39s 482ms/step - loss: 0.2187 - accuracy: 0.9188 - precision: 0.9781 - recall: 0.9236 - f1_score: 0.9501 - true_negative: 70590.3359 - val_loss: 0.0821 - val_accuracy: 0.9701 - val_precision: 0.9786 - val_recall: 0.9259 - val_f1_score: 0.9515 - val_true_negative: 73716.8281\n",
            "Epoch 13/20\n",
            "81/81 [==============================] - 39s 488ms/step - loss: 0.2124 - accuracy: 0.9225 - precision: 0.9788 - recall: 0.9278 - f1_score: 0.9527 - true_negative: 76827.1719 - val_loss: 0.1068 - val_accuracy: 0.9553 - val_precision: 0.9793 - val_recall: 0.9295 - val_f1_score: 0.9537 - val_true_negative: 79953.8281\n",
            "Epoch 14/20\n",
            "81/81 [==============================] - 39s 481ms/step - loss: 0.1878 - accuracy: 0.9268 - precision: 0.9794 - recall: 0.9314 - f1_score: 0.9548 - true_negative: 83075.3203 - val_loss: 0.0701 - val_accuracy: 0.9783 - val_precision: 0.9797 - val_recall: 0.9331 - val_f1_score: 0.9558 - val_true_negative: 86188.8281\n",
            "Epoch 15/20\n",
            "81/81 [==============================] - 39s 483ms/step - loss: 0.2010 - accuracy: 0.9252 - precision: 0.9800 - recall: 0.9347 - f1_score: 0.9569 - true_negative: 89284.8516 - val_loss: 0.1003 - val_accuracy: 0.9616 - val_precision: 0.9803 - val_recall: 0.9361 - val_f1_score: 0.9577 - val_true_negative: 92426.4141\n",
            "Epoch 16/20\n",
            "81/81 [==============================] - 39s 478ms/step - loss: 0.2013 - accuracy: 0.9279 - precision: 0.9805 - recall: 0.9373 - f1_score: 0.9584 - true_negative: 95542.5312 - val_loss: 0.0819 - val_accuracy: 0.9724 - val_precision: 0.9808 - val_recall: 0.9382 - val_f1_score: 0.9590 - val_true_negative: 98664.8281\n",
            "Epoch 17/20\n",
            "81/81 [==============================] - 39s 480ms/step - loss: 0.1645 - accuracy: 0.9371 - precision: 0.9809 - recall: 0.9396 - f1_score: 0.9598 - true_negative: 101791.7812 - val_loss: 0.0747 - val_accuracy: 0.9759 - val_precision: 0.9811 - val_recall: 0.9409 - val_f1_score: 0.9606 - val_true_negative: 104901.8281\n",
            "Epoch 18/20\n",
            "81/81 [==============================] - 39s 481ms/step - loss: 0.1722 - accuracy: 0.9365 - precision: 0.9813 - recall: 0.9419 - f1_score: 0.9612 - true_negative: 108009.4922 - val_loss: 0.0909 - val_accuracy: 0.9670 - val_precision: 0.9815 - val_recall: 0.9427 - val_f1_score: 0.9617 - val_true_negative: 111139.8281\n",
            "Epoch 19/20\n",
            "81/81 [==============================] - 39s 481ms/step - loss: 0.1712 - accuracy: 0.9361 - precision: 0.9818 - recall: 0.9436 - f1_score: 0.9623 - true_negative: 114250.3984 - val_loss: 0.0823 - val_accuracy: 0.9709 - val_precision: 0.9820 - val_recall: 0.9444 - val_f1_score: 0.9629 - val_true_negative: 117382.8281\n",
            "Epoch 20/20\n",
            "81/81 [==============================] - 40s 490ms/step - loss: 0.1665 - accuracy: 0.9359 - precision: 0.9823 - recall: 0.9453 - f1_score: 0.9635 - true_negative: 120481.0391 - val_loss: 0.0810 - val_accuracy: 0.9682 - val_precision: 0.9825 - val_recall: 0.9462 - val_f1_score: 0.9640 - val_true_negative: 123625.8281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm3-0v4OB3K4",
        "outputId": "bccece18-8bb3-45d7-ce2e-d5453d9b9bce"
      },
      "source": [
        "# Testando o model após treinamento\n",
        "x_test_rnn2 = x_test[..., None]\n",
        "test_results = model_hyb.evaluate(x_test_rnn2, y_test, verbose=1)\n",
        "print(f'Loss: {test_results[0]}\\nAccuracy: {test_results[1]}\\nPrecision: {test_results[2]}\\nRecall: {test_results[3]}\\nF1 Score: {test_results[1]}\\nSpecificity: {test_results[1]}')"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81/81 [==============================] - 6s 77ms/step - loss: 0.0697 - accuracy: 0.9709 - precision: 0.9828 - recall: 0.9470 - f1_score: 0.9646 - true_negative: 125705.3125\n",
            "Loss: 0.06966200470924377\n",
            "Accuracy: 0.9708737730979919\n",
            "Precision: 0.9827827215194702\n",
            "Recall: 0.9470177888870239\n",
            "F1 Score: 0.9708737730979919\n",
            "Specificity: 0.9708737730979919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXUffx0Luffl",
        "outputId": "33baa80a-a2b6-4ae0-b750-6bfe882a33c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Testa o treino apenas com a classe LAYING\n",
        "test_results = model_hyb.evaluate(x_test_laying, y_test_laying, verbose=1)\n",
        "print(f'Loss: {test_results[0]}\\nAccuracy: {test_results[1]}\\nPrecision: {test_results[2]}\\nRecall: {test_results[3]}\\nF1 Score: {test_results[1]}\\nSpecificity: {test_results[1]}')"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_metrics/metrics.py:26: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  return object.__getattribute__(self, name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 2s 74ms/step - loss: 0.4044 - accuracy: 0.9160 - precision: 0.9831 - recall: 0.9472 - f1_score: 0.9648 - true_negative: 126728.0000\n",
            "Loss: 0.4043870270252228\n",
            "Accuracy: 0.9159663915634155\n",
            "Precision: 0.9830648303031921\n",
            "Recall: 0.9471865892410278\n",
            "F1 Score: 0.9159663915634155\n",
            "Specificity: 0.9159663915634155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hng_Xo0BhVxq"
      },
      "source": [
        "# Conclusão\n",
        "\n",
        "\n",
        "\n",
        "![image.png](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/table.png)"
      ]
    }
  ]
}