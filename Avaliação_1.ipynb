{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Avaliação_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Le4o/topicos-avancados-ic/blob/main/Avalia%C3%A7%C3%A3o_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph2GsBsm71kL"
      },
      "source": [
        "# Séries Temporais\n",
        "#### Exercício da matéria de Tópicos Avançados em Inteligência Computacional\n",
        "\n",
        "Grupo:\n",
        "- João Victor de Sledz Bulhões\n",
        "- Leonardo de Andrade Santana\n",
        "- Lis da Silva Azevedo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCjtVa-V8-Qq"
      },
      "source": [
        "### Definição do Exercício\n",
        "Utilizaremos o banco de dados do Human Activity Recognition with Smartphones, que foi construído a partir das gravações dos participantes do estudo realizando atividades da vida diária enquanto carregavam um smartphone com sensores inerciais embutidos. Para cada registro no conjunto de dados, é fornecido:\n",
        "\n",
        "- Aceleração triaxial do acelerômetro (aceleração total) e a aceleração corporal estimada.\n",
        "\n",
        "- Velocidade angular triaxial do giroscópio.\n",
        "\n",
        "- Um vetor de 561 atributos com variáveis de domínio de tempo e frequência.\n",
        "\n",
        "- O rótulo da atividade.\n",
        "\n",
        "### Objetivo:\n",
        "* Construir um modelo robusto para classificação das atividades diárias, utilizando o banco de dados fornecido, em uma das seis ações disponíveis:\n",
        "> 1. caminhar;\n",
        "> 2. subir escadas;\n",
        "> 3. descer escadas;\n",
        "> 4. sentar;\n",
        "> 5. ficar em pé;\n",
        "> 6. deitar.\n",
        "\n",
        "* Desenvolver 4 modelos, utilizando:\n",
        "> 1. MLP\n",
        "> 2. CNN\n",
        "> 3. Rede Neural Recorrente\n",
        "> 4. Arquitetura hibrida com a combinação das redes anteriore\n",
        "\n",
        "* Considere a divisão entre treinamento, validação e teste de 50%, 25% e 25%, respectivamente.\n",
        "\n",
        "* Utilizar como métricas: **precision, recall, specificity,\n",
        "F1-Score e accuracy**, evidenciando que o modelo não sofreu de **over/underfitting**.\n",
        "\n",
        "### Observação: \n",
        "*   *Apresentação de métricas, gráficos, são essenciais para entendimento dos modelos e justificativas.*\n",
        "*   *Compare ao final em uma tabela e apresente que técnica obteve os melhores\n",
        "resultados, discutindo-os à luz de seu conhecimento sobre o assunto, discutindo\n",
        "se eram resultados esperados, se estão adequados, e os porquês.*\n",
        "\n",
        "### Opcionais:\n",
        "\n",
        "*   A utilização de redes neurais baseadas em transformers é opcional e adicionará **1,0 ponto extra** ao projeto.\n",
        "*   A utilização de pré-processamento das séries com Wavelets OU transformadas de Fourier adicionará **1,0 ponto extra** ao projeto.\n",
        "\n",
        "\n",
        "### Link:\n",
        "\n",
        "* [Mais informações sobre os recursos estão disponíveis no site](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UF0cRGhDgiY",
        "outputId": "d8947556-84c9-4c8e-d549-11897e98b9ac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive/Datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/Datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9Y0uE6G8Cq7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPcy7yBBJkXe"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cc1HvZ173f4"
      },
      "source": [
        "## Carregando os dados\n",
        "\n",
        "O dataset fornecido é segmentado em **70% treino e 30% teste**, porém a atividade pede para segmentar em: **50% treino, 25% validação e 25% teste.** Então nos primeiramente juntamos os dados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yALQSUMD5W4",
        "outputId": "18a06238-bee3-4d1d-d023-dc110db68d78"
      },
      "source": [
        "# Carregando os dados diretamente dos csvs do Human Activity Recognition with Smartphones\n",
        "train_data = pd.read_csv('./uci_har_csvs/train.csv')\n",
        "test_data = pd.read_csv('./uci_har_csvs/test.csv')\n",
        "\n",
        "print(f'Shape of train data is: {train_data.shape}\\nShape of test data is: {test_data.shape}')\n",
        "\n",
        "data = train_data.append(test_data)\n",
        "data.shape\n",
        "\n",
        "print(f'Shape of combined data is {data.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train data is: (7352, 563)\n",
            "Shape of test data is: (2947, 563)\n",
            "Shape of combined data is (10299, 563)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGe5x0Dw8IMt"
      },
      "source": [
        "## Analise inicial dos dados\n",
        "\n",
        "O dataset possui 6 classes, sendo elas:\n",
        "\n",
        "\n",
        "1.   Walking downstairs\n",
        "2.   Walking Upstairs\n",
        "3.   Walking\n",
        "4.   Sitting\n",
        "5.   Stading \n",
        "6.   Laying\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idSZzsaY20Yn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "8fe9259b-63f6-4bf3-c0f5-5958c56b96b0"
      },
      "source": [
        "class_count = len(data['Activity'].unique())\n",
        "data['Activity'].value_counts().sort_values().plot(kind = 'bar', color = 'pink')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff1b730d750>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRW0Ytg_2hap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "adbfab47-895d-492d-ba65-ec81a63c23b3"
      },
      "source": [
        "train, validate, test = \\\n",
        "              np.split(data.sample(frac=1, random_state=42), \n",
        "                       [int(.5*len(data)), int(.75*len(data))])\n",
        "              \n",
        "print(f'Shape of train data is {train.shape}')\n",
        "print(f'Shape of validation data is {validate.shape}')\n",
        "print(f'Shape of test data is {test.shape}')\n",
        "train.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train data is (5149, 563)\n",
            "Shape of validation data is (2575, 563)\n",
            "Shape of test data is (2575, 563)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tBodyAcc-mean()-X</th>\n",
              "      <th>tBodyAcc-mean()-Y</th>\n",
              "      <th>tBodyAcc-mean()-Z</th>\n",
              "      <th>tBodyAcc-std()-X</th>\n",
              "      <th>tBodyAcc-std()-Y</th>\n",
              "      <th>tBodyAcc-std()-Z</th>\n",
              "      <th>tBodyAcc-mad()-X</th>\n",
              "      <th>tBodyAcc-mad()-Y</th>\n",
              "      <th>tBodyAcc-mad()-Z</th>\n",
              "      <th>tBodyAcc-max()-X</th>\n",
              "      <th>tBodyAcc-max()-Y</th>\n",
              "      <th>tBodyAcc-max()-Z</th>\n",
              "      <th>tBodyAcc-min()-X</th>\n",
              "      <th>tBodyAcc-min()-Y</th>\n",
              "      <th>tBodyAcc-min()-Z</th>\n",
              "      <th>tBodyAcc-sma()</th>\n",
              "      <th>tBodyAcc-energy()-X</th>\n",
              "      <th>tBodyAcc-energy()-Y</th>\n",
              "      <th>tBodyAcc-energy()-Z</th>\n",
              "      <th>tBodyAcc-iqr()-X</th>\n",
              "      <th>tBodyAcc-iqr()-Y</th>\n",
              "      <th>tBodyAcc-iqr()-Z</th>\n",
              "      <th>tBodyAcc-entropy()-X</th>\n",
              "      <th>tBodyAcc-entropy()-Y</th>\n",
              "      <th>tBodyAcc-entropy()-Z</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,4</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,4</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,4</th>\n",
              "      <th>tBodyAcc-correlation()-X,Y</th>\n",
              "      <th>tBodyAcc-correlation()-X,Z</th>\n",
              "      <th>tBodyAcc-correlation()-Y,Z</th>\n",
              "      <th>...</th>\n",
              "      <th>fBodyBodyAccJerkMag-entropy()</th>\n",
              "      <th>fBodyBodyAccJerkMag-maxInds</th>\n",
              "      <th>fBodyBodyAccJerkMag-meanFreq()</th>\n",
              "      <th>fBodyBodyAccJerkMag-skewness()</th>\n",
              "      <th>fBodyBodyAccJerkMag-kurtosis()</th>\n",
              "      <th>fBodyBodyGyroMag-mean()</th>\n",
              "      <th>fBodyBodyGyroMag-std()</th>\n",
              "      <th>fBodyBodyGyroMag-mad()</th>\n",
              "      <th>fBodyBodyGyroMag-max()</th>\n",
              "      <th>fBodyBodyGyroMag-min()</th>\n",
              "      <th>fBodyBodyGyroMag-sma()</th>\n",
              "      <th>fBodyBodyGyroMag-energy()</th>\n",
              "      <th>fBodyBodyGyroMag-iqr()</th>\n",
              "      <th>fBodyBodyGyroMag-entropy()</th>\n",
              "      <th>fBodyBodyGyroMag-maxInds</th>\n",
              "      <th>fBodyBodyGyroMag-meanFreq()</th>\n",
              "      <th>fBodyBodyGyroMag-skewness()</th>\n",
              "      <th>fBodyBodyGyroMag-kurtosis()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-mean()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-std()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-mad()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-max()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-min()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-sma()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-energy()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-iqr()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-entropy()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-maxInds</th>\n",
              "      <th>fBodyBodyGyroJerkMag-meanFreq()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
              "      <th>angle(tBodyAccMean,gravity)</th>\n",
              "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
              "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
              "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
              "      <th>angle(X,gravityMean)</th>\n",
              "      <th>angle(Y,gravityMean)</th>\n",
              "      <th>angle(Z,gravityMean)</th>\n",
              "      <th>subject</th>\n",
              "      <th>Activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5804</th>\n",
              "      <td>0.202351</td>\n",
              "      <td>-0.021717</td>\n",
              "      <td>-0.111851</td>\n",
              "      <td>-0.332095</td>\n",
              "      <td>-0.114114</td>\n",
              "      <td>-0.309439</td>\n",
              "      <td>-0.382582</td>\n",
              "      <td>-0.161981</td>\n",
              "      <td>-0.308824</td>\n",
              "      <td>0.046627</td>\n",
              "      <td>-0.080060</td>\n",
              "      <td>-0.507483</td>\n",
              "      <td>0.275630</td>\n",
              "      <td>0.179982</td>\n",
              "      <td>0.279671</td>\n",
              "      <td>-0.226882</td>\n",
              "      <td>-0.774483</td>\n",
              "      <td>-0.847758</td>\n",
              "      <td>-0.783153</td>\n",
              "      <td>-0.464786</td>\n",
              "      <td>-0.419214</td>\n",
              "      <td>-0.337220</td>\n",
              "      <td>0.299194</td>\n",
              "      <td>0.248520</td>\n",
              "      <td>0.308393</td>\n",
              "      <td>-0.083773</td>\n",
              "      <td>-0.095324</td>\n",
              "      <td>0.361476</td>\n",
              "      <td>-0.110608</td>\n",
              "      <td>-0.126731</td>\n",
              "      <td>0.087686</td>\n",
              "      <td>0.213343</td>\n",
              "      <td>-0.074815</td>\n",
              "      <td>-0.391531</td>\n",
              "      <td>0.548476</td>\n",
              "      <td>-0.344194</td>\n",
              "      <td>-0.002450</td>\n",
              "      <td>-0.138590</td>\n",
              "      <td>-0.160088</td>\n",
              "      <td>0.057044</td>\n",
              "      <td>...</td>\n",
              "      <td>0.305859</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.280790</td>\n",
              "      <td>0.108334</td>\n",
              "      <td>-0.273964</td>\n",
              "      <td>-0.543972</td>\n",
              "      <td>-0.600422</td>\n",
              "      <td>-0.547632</td>\n",
              "      <td>-0.665569</td>\n",
              "      <td>-0.872649</td>\n",
              "      <td>-0.543972</td>\n",
              "      <td>-0.887938</td>\n",
              "      <td>-0.500558</td>\n",
              "      <td>0.496935</td>\n",
              "      <td>-0.589744</td>\n",
              "      <td>0.286247</td>\n",
              "      <td>-0.424845</td>\n",
              "      <td>-0.735574</td>\n",
              "      <td>-0.559849</td>\n",
              "      <td>-0.545961</td>\n",
              "      <td>-0.526840</td>\n",
              "      <td>-0.529618</td>\n",
              "      <td>-0.934321</td>\n",
              "      <td>-0.559849</td>\n",
              "      <td>-0.892957</td>\n",
              "      <td>-0.443799</td>\n",
              "      <td>0.415805</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.068494</td>\n",
              "      <td>0.005777</td>\n",
              "      <td>-0.313236</td>\n",
              "      <td>0.831735</td>\n",
              "      <td>0.495929</td>\n",
              "      <td>-0.021844</td>\n",
              "      <td>-0.621611</td>\n",
              "      <td>-0.843964</td>\n",
              "      <td>0.187828</td>\n",
              "      <td>-0.044740</td>\n",
              "      <td>26</td>\n",
              "      <td>WALKING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3688</th>\n",
              "      <td>0.282814</td>\n",
              "      <td>-0.016686</td>\n",
              "      <td>-0.110004</td>\n",
              "      <td>-0.994285</td>\n",
              "      <td>-0.973997</td>\n",
              "      <td>-0.988410</td>\n",
              "      <td>-0.994069</td>\n",
              "      <td>-0.978087</td>\n",
              "      <td>-0.989570</td>\n",
              "      <td>-0.938192</td>\n",
              "      <td>-0.569563</td>\n",
              "      <td>-0.805062</td>\n",
              "      <td>0.849412</td>\n",
              "      <td>0.672442</td>\n",
              "      <td>0.843429</td>\n",
              "      <td>-0.989757</td>\n",
              "      <td>-0.999954</td>\n",
              "      <td>-0.999771</td>\n",
              "      <td>-0.999777</td>\n",
              "      <td>-0.993230</td>\n",
              "      <td>-0.986070</td>\n",
              "      <td>-0.987647</td>\n",
              "      <td>-0.485685</td>\n",
              "      <td>-0.540288</td>\n",
              "      <td>-0.596279</td>\n",
              "      <td>0.280079</td>\n",
              "      <td>-0.206313</td>\n",
              "      <td>0.056897</td>\n",
              "      <td>0.078721</td>\n",
              "      <td>-0.124651</td>\n",
              "      <td>0.063927</td>\n",
              "      <td>0.050518</td>\n",
              "      <td>0.289955</td>\n",
              "      <td>0.089253</td>\n",
              "      <td>-0.054967</td>\n",
              "      <td>0.070126</td>\n",
              "      <td>0.099666</td>\n",
              "      <td>0.116684</td>\n",
              "      <td>-0.225904</td>\n",
              "      <td>-0.636409</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.809524</td>\n",
              "      <td>0.161835</td>\n",
              "      <td>-0.654476</td>\n",
              "      <td>-0.942112</td>\n",
              "      <td>-0.983364</td>\n",
              "      <td>-0.980910</td>\n",
              "      <td>-0.977646</td>\n",
              "      <td>-0.984225</td>\n",
              "      <td>-0.997516</td>\n",
              "      <td>-0.983364</td>\n",
              "      <td>-0.999731</td>\n",
              "      <td>-0.984269</td>\n",
              "      <td>-0.671366</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.289716</td>\n",
              "      <td>-0.525437</td>\n",
              "      <td>-0.821969</td>\n",
              "      <td>-0.989797</td>\n",
              "      <td>-0.987181</td>\n",
              "      <td>-0.988234</td>\n",
              "      <td>-0.987283</td>\n",
              "      <td>-0.993587</td>\n",
              "      <td>-0.989797</td>\n",
              "      <td>-0.999899</td>\n",
              "      <td>-0.989580</td>\n",
              "      <td>-0.895847</td>\n",
              "      <td>-0.968254</td>\n",
              "      <td>-0.076563</td>\n",
              "      <td>0.037980</td>\n",
              "      <td>-0.366579</td>\n",
              "      <td>0.072845</td>\n",
              "      <td>-0.622912</td>\n",
              "      <td>-0.090463</td>\n",
              "      <td>0.313810</td>\n",
              "      <td>0.592963</td>\n",
              "      <td>-0.576030</td>\n",
              "      <td>-0.428127</td>\n",
              "      <td>19</td>\n",
              "      <td>LAYING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.272529</td>\n",
              "      <td>-0.020954</td>\n",
              "      <td>-0.114472</td>\n",
              "      <td>-0.996784</td>\n",
              "      <td>-0.975906</td>\n",
              "      <td>-0.986597</td>\n",
              "      <td>-0.997029</td>\n",
              "      <td>-0.973735</td>\n",
              "      <td>-0.985556</td>\n",
              "      <td>-0.941263</td>\n",
              "      <td>-0.564290</td>\n",
              "      <td>-0.821296</td>\n",
              "      <td>0.849753</td>\n",
              "      <td>0.686588</td>\n",
              "      <td>0.840875</td>\n",
              "      <td>-0.987390</td>\n",
              "      <td>-0.999976</td>\n",
              "      <td>-0.999771</td>\n",
              "      <td>-0.999679</td>\n",
              "      <td>-0.996962</td>\n",
              "      <td>-0.972932</td>\n",
              "      <td>-0.982118</td>\n",
              "      <td>-0.751029</td>\n",
              "      <td>-0.595825</td>\n",
              "      <td>-0.615634</td>\n",
              "      <td>0.179165</td>\n",
              "      <td>-0.117050</td>\n",
              "      <td>0.148687</td>\n",
              "      <td>-0.082409</td>\n",
              "      <td>0.188682</td>\n",
              "      <td>-0.102966</td>\n",
              "      <td>0.059483</td>\n",
              "      <td>-0.078121</td>\n",
              "      <td>0.187768</td>\n",
              "      <td>-0.106895</td>\n",
              "      <td>0.010262</td>\n",
              "      <td>0.092770</td>\n",
              "      <td>0.049340</td>\n",
              "      <td>0.171381</td>\n",
              "      <td>0.458159</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.968254</td>\n",
              "      <td>0.382158</td>\n",
              "      <td>-0.764742</td>\n",
              "      <td>-0.973118</td>\n",
              "      <td>-0.995873</td>\n",
              "      <td>-0.995513</td>\n",
              "      <td>-0.995051</td>\n",
              "      <td>-0.995946</td>\n",
              "      <td>-0.996275</td>\n",
              "      <td>-0.995873</td>\n",
              "      <td>-0.999973</td>\n",
              "      <td>-0.994379</td>\n",
              "      <td>-0.924075</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.082496</td>\n",
              "      <td>-0.530473</td>\n",
              "      <td>-0.815909</td>\n",
              "      <td>-0.997398</td>\n",
              "      <td>-0.997519</td>\n",
              "      <td>-0.997132</td>\n",
              "      <td>-0.997812</td>\n",
              "      <td>-0.998136</td>\n",
              "      <td>-0.997398</td>\n",
              "      <td>-0.999989</td>\n",
              "      <td>-0.996639</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.841270</td>\n",
              "      <td>0.283428</td>\n",
              "      <td>-0.629599</td>\n",
              "      <td>-0.853248</td>\n",
              "      <td>0.144626</td>\n",
              "      <td>-0.035564</td>\n",
              "      <td>-0.181800</td>\n",
              "      <td>0.087320</td>\n",
              "      <td>-0.685390</td>\n",
              "      <td>0.299394</td>\n",
              "      <td>-0.065491</td>\n",
              "      <td>2</td>\n",
              "      <td>STANDING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3437</th>\n",
              "      <td>0.276408</td>\n",
              "      <td>-0.024315</td>\n",
              "      <td>-0.101067</td>\n",
              "      <td>-0.995663</td>\n",
              "      <td>-0.973317</td>\n",
              "      <td>-0.976591</td>\n",
              "      <td>-0.996090</td>\n",
              "      <td>-0.970965</td>\n",
              "      <td>-0.973102</td>\n",
              "      <td>-0.940314</td>\n",
              "      <td>-0.564623</td>\n",
              "      <td>-0.809686</td>\n",
              "      <td>0.847186</td>\n",
              "      <td>0.680895</td>\n",
              "      <td>0.842424</td>\n",
              "      <td>-0.982602</td>\n",
              "      <td>-0.999972</td>\n",
              "      <td>-0.999670</td>\n",
              "      <td>-0.999352</td>\n",
              "      <td>-0.995961</td>\n",
              "      <td>-0.974512</td>\n",
              "      <td>-0.965379</td>\n",
              "      <td>-0.639349</td>\n",
              "      <td>-0.648505</td>\n",
              "      <td>-0.378690</td>\n",
              "      <td>0.288604</td>\n",
              "      <td>-0.171739</td>\n",
              "      <td>-0.063385</td>\n",
              "      <td>0.240414</td>\n",
              "      <td>0.137930</td>\n",
              "      <td>-0.152519</td>\n",
              "      <td>0.289294</td>\n",
              "      <td>-0.306233</td>\n",
              "      <td>0.134866</td>\n",
              "      <td>-0.050976</td>\n",
              "      <td>0.018678</td>\n",
              "      <td>-0.238603</td>\n",
              "      <td>0.571580</td>\n",
              "      <td>-0.305336</td>\n",
              "      <td>-0.422931</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.873016</td>\n",
              "      <td>0.249802</td>\n",
              "      <td>-0.572081</td>\n",
              "      <td>-0.903342</td>\n",
              "      <td>-0.995015</td>\n",
              "      <td>-0.994365</td>\n",
              "      <td>-0.993413</td>\n",
              "      <td>-0.994503</td>\n",
              "      <td>-0.999366</td>\n",
              "      <td>-0.995015</td>\n",
              "      <td>-0.999963</td>\n",
              "      <td>-0.992369</td>\n",
              "      <td>-0.896695</td>\n",
              "      <td>-0.897436</td>\n",
              "      <td>0.033944</td>\n",
              "      <td>-0.498391</td>\n",
              "      <td>-0.775560</td>\n",
              "      <td>-0.997580</td>\n",
              "      <td>-0.998807</td>\n",
              "      <td>-0.998611</td>\n",
              "      <td>-0.999015</td>\n",
              "      <td>-0.996673</td>\n",
              "      <td>-0.997580</td>\n",
              "      <td>-0.999992</td>\n",
              "      <td>-0.998166</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.521509</td>\n",
              "      <td>-0.788724</td>\n",
              "      <td>-0.937673</td>\n",
              "      <td>-0.093666</td>\n",
              "      <td>0.010872</td>\n",
              "      <td>-0.407271</td>\n",
              "      <td>-0.340803</td>\n",
              "      <td>-0.704093</td>\n",
              "      <td>0.297943</td>\n",
              "      <td>0.061830</td>\n",
              "      <td>17</td>\n",
              "      <td>STANDING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841</th>\n",
              "      <td>0.306400</td>\n",
              "      <td>-0.013045</td>\n",
              "      <td>-0.064768</td>\n",
              "      <td>-0.180371</td>\n",
              "      <td>-0.099780</td>\n",
              "      <td>-0.002085</td>\n",
              "      <td>-0.204581</td>\n",
              "      <td>-0.082737</td>\n",
              "      <td>0.031456</td>\n",
              "      <td>-0.095405</td>\n",
              "      <td>0.036683</td>\n",
              "      <td>-0.294994</td>\n",
              "      <td>0.174304</td>\n",
              "      <td>0.304617</td>\n",
              "      <td>0.324272</td>\n",
              "      <td>-0.008168</td>\n",
              "      <td>-0.662743</td>\n",
              "      <td>-0.842857</td>\n",
              "      <td>-0.550885</td>\n",
              "      <td>-0.226231</td>\n",
              "      <td>-0.220124</td>\n",
              "      <td>0.058503</td>\n",
              "      <td>0.323706</td>\n",
              "      <td>0.254981</td>\n",
              "      <td>0.398452</td>\n",
              "      <td>-0.669520</td>\n",
              "      <td>0.563266</td>\n",
              "      <td>-0.123948</td>\n",
              "      <td>-0.043125</td>\n",
              "      <td>-0.053111</td>\n",
              "      <td>0.118593</td>\n",
              "      <td>0.080800</td>\n",
              "      <td>0.331881</td>\n",
              "      <td>-0.368409</td>\n",
              "      <td>0.400530</td>\n",
              "      <td>-0.533170</td>\n",
              "      <td>0.396705</td>\n",
              "      <td>0.034912</td>\n",
              "      <td>-0.143363</td>\n",
              "      <td>-0.307109</td>\n",
              "      <td>...</td>\n",
              "      <td>0.352066</td>\n",
              "      <td>-0.873016</td>\n",
              "      <td>0.124461</td>\n",
              "      <td>0.174304</td>\n",
              "      <td>-0.084459</td>\n",
              "      <td>-0.477451</td>\n",
              "      <td>-0.554138</td>\n",
              "      <td>-0.478395</td>\n",
              "      <td>-0.635942</td>\n",
              "      <td>-0.952267</td>\n",
              "      <td>-0.477451</td>\n",
              "      <td>-0.857192</td>\n",
              "      <td>-0.577590</td>\n",
              "      <td>0.555212</td>\n",
              "      <td>-0.692308</td>\n",
              "      <td>0.159567</td>\n",
              "      <td>-0.506231</td>\n",
              "      <td>-0.808295</td>\n",
              "      <td>-0.491858</td>\n",
              "      <td>-0.542730</td>\n",
              "      <td>-0.526277</td>\n",
              "      <td>-0.518852</td>\n",
              "      <td>-0.740293</td>\n",
              "      <td>-0.491858</td>\n",
              "      <td>-0.872992</td>\n",
              "      <td>-0.577415</td>\n",
              "      <td>0.441255</td>\n",
              "      <td>-0.873016</td>\n",
              "      <td>0.426281</td>\n",
              "      <td>-0.009035</td>\n",
              "      <td>-0.338551</td>\n",
              "      <td>-0.090383</td>\n",
              "      <td>-0.780317</td>\n",
              "      <td>-0.845675</td>\n",
              "      <td>-0.048851</td>\n",
              "      <td>-0.751484</td>\n",
              "      <td>0.069695</td>\n",
              "      <td>0.196049</td>\n",
              "      <td>9</td>\n",
              "      <td>WALKING</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 563 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      tBodyAcc-mean()-X  tBodyAcc-mean()-Y  ...  subject  Activity\n",
              "5804           0.202351          -0.021717  ...       26   WALKING\n",
              "3688           0.282814          -0.016686  ...       19    LAYING\n",
              "8              0.272529          -0.020954  ...        2  STANDING\n",
              "3437           0.276408          -0.024315  ...       17  STANDING\n",
              "841            0.306400          -0.013045  ...        9   WALKING\n",
              "\n",
              "[5 rows x 563 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6waF_f25De4J"
      },
      "source": [
        "# MLP\n",
        "Criando modelo de MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMUk5T3yIm_S"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTcaNixfDRD7",
        "outputId": "0d3c5385-b847-4ac6-bed5-9994b33d2979",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Separando os os dados do target\n",
        "x_train, y_train = train.iloc[:, :-2], train.iloc[:, -1:]\n",
        "x_test, y_test = test.iloc[:, :-2], test.iloc[:, -1:]\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5149, 561), (5149, 1), (2575, 561), (2575, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_78axvFL4V_"
      },
      "source": [
        "# Trasformando as strings do target em números\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.fit_transform(y_test)\n",
        "\n",
        "# --------------Não sei oq é isso\n",
        "scaling_data = MinMaxScaler()\n",
        "x_train = scaling_data.fit_transform(x_train)\n",
        "x_test = scaling_data.transform(x_test)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmF9XuyDG6dz",
        "outputId": "ed8e74e6-d9a5-454a-a9ec-f35c418ce82f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Criando o model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=64,kernel_initializer='normal', activation='sigmoid', input_dim=x_train.shape[1]))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=6,kernel_initializer='normal', activation='softmax'))\n",
        "\n",
        "# Compilando o model e treinando\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, batch_size=64, epochs=20, validation_data=(x_test,y_test))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "81/81 [==============================] - 1s 5ms/step - loss: 1.4176 - accuracy: 0.4172 - val_loss: 1.1291 - val_accuracy: 0.4322\n",
            "Epoch 2/20\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.0338 - accuracy: 0.6182 - val_loss: 0.9183 - val_accuracy: 0.8276\n",
            "Epoch 3/20\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8134 - accuracy: 0.7568 - val_loss: 0.6984 - val_accuracy: 0.8241\n",
            "Epoch 4/20\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.8054 - val_loss: 0.5510 - val_accuracy: 0.8800\n",
            "Epoch 5/20\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.8363 - val_loss: 0.4534 - val_accuracy: 0.8913\n",
            "Epoch 6/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.8586 - val_loss: 0.3867 - val_accuracy: 0.8986\n",
            "Epoch 7/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.8743 - val_loss: 0.3368 - val_accuracy: 0.8920\n",
            "Epoch 8/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.3393 - accuracy: 0.8909 - val_loss: 0.2973 - val_accuracy: 0.9122\n",
            "Epoch 9/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8982 - val_loss: 0.2631 - val_accuracy: 0.9262\n",
            "Epoch 10/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.2797 - accuracy: 0.9066 - val_loss: 0.2375 - val_accuracy: 0.9270\n",
            "Epoch 11/20\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.2530 - accuracy: 0.9161 - val_loss: 0.2210 - val_accuracy: 0.9282\n",
            "Epoch 12/20\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.2387 - accuracy: 0.9182 - val_loss: 0.2056 - val_accuracy: 0.9293\n",
            "Epoch 13/20\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9254 - val_loss: 0.1873 - val_accuracy: 0.9394\n",
            "Epoch 14/20\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9258 - val_loss: 0.1812 - val_accuracy: 0.9367\n",
            "Epoch 15/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1961 - accuracy: 0.9324 - val_loss: 0.1666 - val_accuracy: 0.9421\n",
            "Epoch 16/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1847 - accuracy: 0.9344 - val_loss: 0.1568 - val_accuracy: 0.9507\n",
            "Epoch 17/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1760 - accuracy: 0.9388 - val_loss: 0.1513 - val_accuracy: 0.9433\n",
            "Epoch 18/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1685 - accuracy: 0.9404 - val_loss: 0.1437 - val_accuracy: 0.9522\n",
            "Epoch 19/20\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9443 - val_loss: 0.1399 - val_accuracy: 0.9499\n",
            "Epoch 20/20\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1517 - accuracy: 0.9513 - val_loss: 0.1327 - val_accuracy: 0.9526\n"
          ]
        }
      ]
    }
  ]
}