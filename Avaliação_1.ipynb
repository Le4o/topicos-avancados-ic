{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Avaliação_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Le4o/topicos-avancados-ic/blob/main/Avalia%C3%A7%C3%A3o_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph2GsBsm71kL"
      },
      "source": [
        "# Séries Temporais\n",
        "#### Exercício da matéria de Tópicos Avançados em Inteligência Computacional\n",
        "\n",
        "Grupo:\n",
        "- João Victor de Sledz Bulhões\n",
        "- Leonardo de Andrade Santana\n",
        "- Lis da Silva Azevedo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCjtVa-V8-Qq"
      },
      "source": [
        "### Definição do Exercício\n",
        "Utilizaremos o banco de dados do Human Activity Recognition with Smartphones, que foi construído a partir das gravações dos participantes do estudo realizando atividades da vida diária enquanto carregavam um smartphone com sensores inerciais embutidos. Para cada registro no conjunto de dados, é fornecido:\n",
        "\n",
        "- Aceleração triaxial do acelerômetro (aceleração total) e a aceleração corporal estimada.\n",
        "\n",
        "- Velocidade angular triaxial do giroscópio.\n",
        "\n",
        "- Um vetor de 561 atributos com variáveis de domínio de tempo e frequência.\n",
        "\n",
        "- O rótulo da atividade.\n",
        "\n",
        "### Objetivo:\n",
        "* Construir um modelo robusto para classificação das atividades diárias, utilizando o banco de dados fornecido, em uma das seis ações disponíveis:\n",
        "> 1. caminhar;\n",
        "> 2. subir escadas;\n",
        "> 3. descer escadas;\n",
        "> 4. sentar;\n",
        "> 5. ficar em pé;\n",
        "> 6. deitar.\n",
        "\n",
        "* Desenvolver 4 modelos, utilizando:\n",
        "> 1. Multi-Layer Perceptron (MLP)\n",
        "> 2. Convolutional Neural Network (CNN)\n",
        "> 3. Recurrent Neural Network (RNN)\n",
        "> 4. Arquitetura hibrida com a combinação das redes anteriore\n",
        "\n",
        "* Considere a divisão entre treinamento, validação e teste de 50%, 25% e 25%, respectivamente.\n",
        "\n",
        "* Utilizar como métricas: **precision, recall, specificity,\n",
        "F1-Score e accuracy**, evidenciando que o modelo não sofreu de **over/underfitting**.\n",
        "\n",
        "### Observação: \n",
        "*   *Apresentação de métricas, gráficos, são essenciais para entendimento dos modelos e justificativas.*\n",
        "*   *Compare ao final em uma tabela e apresente que técnica obteve os melhores\n",
        "resultados, discutindo-os à luz de seu conhecimento sobre o assunto, discutindo\n",
        "se eram resultados esperados, se estão adequados, e os porquês.*\n",
        "\n",
        "### Opcionais:\n",
        "\n",
        "*   A utilização de redes neurais baseadas em transformers é opcional e adicionará **1,0 ponto extra** ao projeto.\n",
        "*   A utilização de pré-processamento das séries com Wavelets OU transformadas de Fourier adicionará **1,0 ponto extra** ao projeto.\n",
        "\n",
        "\n",
        "### Link:\n",
        "\n",
        "* [Mais informações sobre os recursos estão disponíveis no site](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UF0cRGhDgiY",
        "outputId": "351188dc-ef40-4dc1-9a5f-c5a24e13cfd3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive/Datasets"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/My Drive/Datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9Y0uE6G8Cq7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPcy7yBBJkXe"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from tensorflow.keras.layers import Dense, Dropout, MaxPooling1D, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cc1HvZ173f4"
      },
      "source": [
        "## Carregando os dados\n",
        "\n",
        "O dataset fornecido é segmentado em **70% treino e 30% teste**, porém a atividade pede para segmentar em: **50% treino, 25% validação e 25% teste.** Então nos primeiramente juntamos os dados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yALQSUMD5W4",
        "outputId": "a41acea0-dcc6-4024-dc19-55348ec1cbff"
      },
      "source": [
        "# Carregando os dados diretamente dos csvs do Human Activity Recognition with Smartphones\n",
        "train_data = pd.read_csv('./uci_har_csvs/train.csv')\n",
        "test_data = pd.read_csv('./uci_har_csvs/test.csv')\n",
        "\n",
        "print(f'Shape of train data is: {train_data.shape}\\nShape of test data is: {test_data.shape}')\n",
        "\n",
        "data = train_data.append(test_data)\n",
        "data.shape\n",
        "\n",
        "print(f'Shape of combined data is {data.shape}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train data is: (7352, 563)\n",
            "Shape of test data is: (2947, 563)\n",
            "Shape of combined data is (10299, 563)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGe5x0Dw8IMt"
      },
      "source": [
        "## Analise inicial dos dados\n",
        "\n",
        "O dataset possui 6 classes, sendo elas:\n",
        "\n",
        "\n",
        "1.   Walking downstairs\n",
        "2.   Walking Upstairs\n",
        "3.   Walking\n",
        "4.   Sitting\n",
        "5.   Stading \n",
        "6.   Laying\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idSZzsaY20Yn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7e73fddb-ff8f-47c9-c291-aa39f4d4e469"
      },
      "source": [
        "class_count = len(data['Activity'].unique())\n",
        "data['Activity'].value_counts().sort_values().plot(kind = 'bar', color = 'pink')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2272d7f290>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6laf9fa7L6w"
      },
      "source": [
        "## Segmentação do Dataset\n",
        "\n",
        "50% treino, 25% validação e 25% teste\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRW0Ytg_2hap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "6ab18401-c61b-4893-fb26-a796ab7381d7"
      },
      "source": [
        "train, validate, test = \\\n",
        "              np.split(data.sample(frac=1, random_state=42), \n",
        "                       [int(.5*len(data)), int(.75*len(data))])\n",
        "              \n",
        "print(f'Shape of train data is {train.shape}')\n",
        "print(f'Shape of validation data is {validate.shape}')\n",
        "print(f'Shape of test data is {test.shape}')\n",
        "validate.head()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train data is (5149, 563)\n",
            "Shape of validation data is (2575, 563)\n",
            "Shape of test data is (2575, 563)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tBodyAcc-mean()-X</th>\n",
              "      <th>tBodyAcc-mean()-Y</th>\n",
              "      <th>tBodyAcc-mean()-Z</th>\n",
              "      <th>tBodyAcc-std()-X</th>\n",
              "      <th>tBodyAcc-std()-Y</th>\n",
              "      <th>tBodyAcc-std()-Z</th>\n",
              "      <th>tBodyAcc-mad()-X</th>\n",
              "      <th>tBodyAcc-mad()-Y</th>\n",
              "      <th>tBodyAcc-mad()-Z</th>\n",
              "      <th>tBodyAcc-max()-X</th>\n",
              "      <th>tBodyAcc-max()-Y</th>\n",
              "      <th>tBodyAcc-max()-Z</th>\n",
              "      <th>tBodyAcc-min()-X</th>\n",
              "      <th>tBodyAcc-min()-Y</th>\n",
              "      <th>tBodyAcc-min()-Z</th>\n",
              "      <th>tBodyAcc-sma()</th>\n",
              "      <th>tBodyAcc-energy()-X</th>\n",
              "      <th>tBodyAcc-energy()-Y</th>\n",
              "      <th>tBodyAcc-energy()-Z</th>\n",
              "      <th>tBodyAcc-iqr()-X</th>\n",
              "      <th>tBodyAcc-iqr()-Y</th>\n",
              "      <th>tBodyAcc-iqr()-Z</th>\n",
              "      <th>tBodyAcc-entropy()-X</th>\n",
              "      <th>tBodyAcc-entropy()-Y</th>\n",
              "      <th>tBodyAcc-entropy()-Z</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,4</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,4</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,4</th>\n",
              "      <th>tBodyAcc-correlation()-X,Y</th>\n",
              "      <th>tBodyAcc-correlation()-X,Z</th>\n",
              "      <th>tBodyAcc-correlation()-Y,Z</th>\n",
              "      <th>...</th>\n",
              "      <th>fBodyBodyAccJerkMag-entropy()</th>\n",
              "      <th>fBodyBodyAccJerkMag-maxInds</th>\n",
              "      <th>fBodyBodyAccJerkMag-meanFreq()</th>\n",
              "      <th>fBodyBodyAccJerkMag-skewness()</th>\n",
              "      <th>fBodyBodyAccJerkMag-kurtosis()</th>\n",
              "      <th>fBodyBodyGyroMag-mean()</th>\n",
              "      <th>fBodyBodyGyroMag-std()</th>\n",
              "      <th>fBodyBodyGyroMag-mad()</th>\n",
              "      <th>fBodyBodyGyroMag-max()</th>\n",
              "      <th>fBodyBodyGyroMag-min()</th>\n",
              "      <th>fBodyBodyGyroMag-sma()</th>\n",
              "      <th>fBodyBodyGyroMag-energy()</th>\n",
              "      <th>fBodyBodyGyroMag-iqr()</th>\n",
              "      <th>fBodyBodyGyroMag-entropy()</th>\n",
              "      <th>fBodyBodyGyroMag-maxInds</th>\n",
              "      <th>fBodyBodyGyroMag-meanFreq()</th>\n",
              "      <th>fBodyBodyGyroMag-skewness()</th>\n",
              "      <th>fBodyBodyGyroMag-kurtosis()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-mean()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-std()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-mad()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-max()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-min()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-sma()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-energy()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-iqr()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-entropy()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-maxInds</th>\n",
              "      <th>fBodyBodyGyroJerkMag-meanFreq()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
              "      <th>angle(tBodyAccMean,gravity)</th>\n",
              "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
              "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
              "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
              "      <th>angle(X,gravityMean)</th>\n",
              "      <th>angle(Y,gravityMean)</th>\n",
              "      <th>angle(Z,gravityMean)</th>\n",
              "      <th>subject</th>\n",
              "      <th>Activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2117</th>\n",
              "      <td>0.274369</td>\n",
              "      <td>-0.016706</td>\n",
              "      <td>-0.110229</td>\n",
              "      <td>-0.991515</td>\n",
              "      <td>-0.989040</td>\n",
              "      <td>-0.978536</td>\n",
              "      <td>-0.992510</td>\n",
              "      <td>-0.990249</td>\n",
              "      <td>-0.980843</td>\n",
              "      <td>-0.936067</td>\n",
              "      <td>-0.561457</td>\n",
              "      <td>-0.812424</td>\n",
              "      <td>0.841441</td>\n",
              "      <td>0.691739</td>\n",
              "      <td>0.824627</td>\n",
              "      <td>-0.989752</td>\n",
              "      <td>-0.999926</td>\n",
              "      <td>-0.999935</td>\n",
              "      <td>-0.999490</td>\n",
              "      <td>-0.994133</td>\n",
              "      <td>-0.991564</td>\n",
              "      <td>-0.983694</td>\n",
              "      <td>-0.570835</td>\n",
              "      <td>-0.632256</td>\n",
              "      <td>-0.525435</td>\n",
              "      <td>0.194450</td>\n",
              "      <td>-0.146492</td>\n",
              "      <td>-0.041534</td>\n",
              "      <td>0.385220</td>\n",
              "      <td>0.146668</td>\n",
              "      <td>0.008702</td>\n",
              "      <td>0.117522</td>\n",
              "      <td>0.316987</td>\n",
              "      <td>0.049494</td>\n",
              "      <td>0.002990</td>\n",
              "      <td>0.077043</td>\n",
              "      <td>-0.040535</td>\n",
              "      <td>-0.326617</td>\n",
              "      <td>-0.124434</td>\n",
              "      <td>-0.467705</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.189798</td>\n",
              "      <td>-0.435028</td>\n",
              "      <td>-0.826468</td>\n",
              "      <td>-0.983336</td>\n",
              "      <td>-0.983446</td>\n",
              "      <td>-0.979036</td>\n",
              "      <td>-0.988786</td>\n",
              "      <td>-0.996133</td>\n",
              "      <td>-0.983336</td>\n",
              "      <td>-0.999768</td>\n",
              "      <td>-0.973804</td>\n",
              "      <td>-0.651509</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.200696</td>\n",
              "      <td>-0.692462</td>\n",
              "      <td>-0.925401</td>\n",
              "      <td>-0.990613</td>\n",
              "      <td>-0.989842</td>\n",
              "      <td>-0.989335</td>\n",
              "      <td>-0.990264</td>\n",
              "      <td>-0.995010</td>\n",
              "      <td>-0.990613</td>\n",
              "      <td>-0.999922</td>\n",
              "      <td>-0.988997</td>\n",
              "      <td>-0.923452</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.165418</td>\n",
              "      <td>-0.227327</td>\n",
              "      <td>-0.592258</td>\n",
              "      <td>-0.031017</td>\n",
              "      <td>-0.068529</td>\n",
              "      <td>0.222656</td>\n",
              "      <td>-0.171256</td>\n",
              "      <td>0.365294</td>\n",
              "      <td>-0.846661</td>\n",
              "      <td>-0.004809</td>\n",
              "      <td>11</td>\n",
              "      <td>LAYING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2937</th>\n",
              "      <td>0.260018</td>\n",
              "      <td>-0.008491</td>\n",
              "      <td>-0.117588</td>\n",
              "      <td>-0.935685</td>\n",
              "      <td>-0.670521</td>\n",
              "      <td>-0.875247</td>\n",
              "      <td>-0.959882</td>\n",
              "      <td>-0.805597</td>\n",
              "      <td>-0.907493</td>\n",
              "      <td>-0.892596</td>\n",
              "      <td>-0.146449</td>\n",
              "      <td>-0.774665</td>\n",
              "      <td>0.710398</td>\n",
              "      <td>0.541556</td>\n",
              "      <td>0.691246</td>\n",
              "      <td>-0.910007</td>\n",
              "      <td>-0.997606</td>\n",
              "      <td>-0.978016</td>\n",
              "      <td>-0.991313</td>\n",
              "      <td>-0.995422</td>\n",
              "      <td>-0.989595</td>\n",
              "      <td>-0.963853</td>\n",
              "      <td>-0.310086</td>\n",
              "      <td>-0.398456</td>\n",
              "      <td>-0.248864</td>\n",
              "      <td>-0.508756</td>\n",
              "      <td>0.476951</td>\n",
              "      <td>-0.460860</td>\n",
              "      <td>0.392226</td>\n",
              "      <td>-0.604299</td>\n",
              "      <td>0.591770</td>\n",
              "      <td>-0.713939</td>\n",
              "      <td>0.839213</td>\n",
              "      <td>-0.252033</td>\n",
              "      <td>0.355529</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.296486</td>\n",
              "      <td>-0.012320</td>\n",
              "      <td>-0.867214</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.476360</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.455206</td>\n",
              "      <td>0.384570</td>\n",
              "      <td>0.087227</td>\n",
              "      <td>-0.512505</td>\n",
              "      <td>-0.269562</td>\n",
              "      <td>-0.408939</td>\n",
              "      <td>-0.192944</td>\n",
              "      <td>-0.049099</td>\n",
              "      <td>-0.512505</td>\n",
              "      <td>-0.740628</td>\n",
              "      <td>-0.801698</td>\n",
              "      <td>0.130729</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.259452</td>\n",
              "      <td>0.265055</td>\n",
              "      <td>-0.064927</td>\n",
              "      <td>-0.929913</td>\n",
              "      <td>-0.863376</td>\n",
              "      <td>-0.907363</td>\n",
              "      <td>-0.843969</td>\n",
              "      <td>-0.985603</td>\n",
              "      <td>-0.929913</td>\n",
              "      <td>-0.993913</td>\n",
              "      <td>-0.935197</td>\n",
              "      <td>-0.419270</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.563006</td>\n",
              "      <td>0.783258</td>\n",
              "      <td>0.551519</td>\n",
              "      <td>0.351286</td>\n",
              "      <td>0.079468</td>\n",
              "      <td>0.329166</td>\n",
              "      <td>0.006809</td>\n",
              "      <td>-0.885412</td>\n",
              "      <td>0.113755</td>\n",
              "      <td>0.100170</td>\n",
              "      <td>16</td>\n",
              "      <td>SITTING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6867</th>\n",
              "      <td>0.278964</td>\n",
              "      <td>-0.016177</td>\n",
              "      <td>-0.112617</td>\n",
              "      <td>-0.986395</td>\n",
              "      <td>-0.993402</td>\n",
              "      <td>-0.996253</td>\n",
              "      <td>-0.987809</td>\n",
              "      <td>-0.994375</td>\n",
              "      <td>-0.995559</td>\n",
              "      <td>-0.935219</td>\n",
              "      <td>-0.566172</td>\n",
              "      <td>-0.826331</td>\n",
              "      <td>0.838379</td>\n",
              "      <td>0.692073</td>\n",
              "      <td>0.845662</td>\n",
              "      <td>-0.992035</td>\n",
              "      <td>-0.999849</td>\n",
              "      <td>-0.999965</td>\n",
              "      <td>-0.999920</td>\n",
              "      <td>-0.989898</td>\n",
              "      <td>-0.995405</td>\n",
              "      <td>-0.992992</td>\n",
              "      <td>-0.391655</td>\n",
              "      <td>-0.668624</td>\n",
              "      <td>-0.735404</td>\n",
              "      <td>0.074098</td>\n",
              "      <td>-0.024003</td>\n",
              "      <td>-0.086759</td>\n",
              "      <td>-0.050424</td>\n",
              "      <td>0.497133</td>\n",
              "      <td>-0.308945</td>\n",
              "      <td>0.436123</td>\n",
              "      <td>-0.284634</td>\n",
              "      <td>0.562480</td>\n",
              "      <td>-0.303941</td>\n",
              "      <td>0.243113</td>\n",
              "      <td>-0.238292</td>\n",
              "      <td>-0.560531</td>\n",
              "      <td>-0.482763</td>\n",
              "      <td>0.529234</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.746032</td>\n",
              "      <td>0.201563</td>\n",
              "      <td>-0.661723</td>\n",
              "      <td>-0.919496</td>\n",
              "      <td>-0.963026</td>\n",
              "      <td>-0.936948</td>\n",
              "      <td>-0.955237</td>\n",
              "      <td>-0.922671</td>\n",
              "      <td>-0.973526</td>\n",
              "      <td>-0.963026</td>\n",
              "      <td>-0.998002</td>\n",
              "      <td>-0.980297</td>\n",
              "      <td>-0.508129</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.242515</td>\n",
              "      <td>0.564836</td>\n",
              "      <td>0.361085</td>\n",
              "      <td>-0.997792</td>\n",
              "      <td>-0.997197</td>\n",
              "      <td>-0.997178</td>\n",
              "      <td>-0.997628</td>\n",
              "      <td>-0.995845</td>\n",
              "      <td>-0.997792</td>\n",
              "      <td>-0.999990</td>\n",
              "      <td>-0.997452</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.650794</td>\n",
              "      <td>0.391506</td>\n",
              "      <td>-0.412803</td>\n",
              "      <td>-0.785954</td>\n",
              "      <td>0.126507</td>\n",
              "      <td>0.229589</td>\n",
              "      <td>-0.420273</td>\n",
              "      <td>0.306465</td>\n",
              "      <td>0.496486</td>\n",
              "      <td>-0.614039</td>\n",
              "      <td>-0.381354</td>\n",
              "      <td>29</td>\n",
              "      <td>LAYING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>0.183580</td>\n",
              "      <td>-0.127213</td>\n",
              "      <td>-0.053418</td>\n",
              "      <td>0.066369</td>\n",
              "      <td>0.175940</td>\n",
              "      <td>-0.392213</td>\n",
              "      <td>0.024724</td>\n",
              "      <td>0.176251</td>\n",
              "      <td>-0.373970</td>\n",
              "      <td>0.026905</td>\n",
              "      <td>-0.011366</td>\n",
              "      <td>-0.414110</td>\n",
              "      <td>-0.061307</td>\n",
              "      <td>-0.120410</td>\n",
              "      <td>0.453433</td>\n",
              "      <td>0.075900</td>\n",
              "      <td>-0.429020</td>\n",
              "      <td>-0.711465</td>\n",
              "      <td>-0.826533</td>\n",
              "      <td>-0.026840</td>\n",
              "      <td>-0.006198</td>\n",
              "      <td>-0.409776</td>\n",
              "      <td>0.363369</td>\n",
              "      <td>0.033249</td>\n",
              "      <td>0.151558</td>\n",
              "      <td>-0.422318</td>\n",
              "      <td>0.161796</td>\n",
              "      <td>0.187022</td>\n",
              "      <td>-0.033507</td>\n",
              "      <td>-0.540551</td>\n",
              "      <td>0.463843</td>\n",
              "      <td>-0.051249</td>\n",
              "      <td>-0.049775</td>\n",
              "      <td>-0.322750</td>\n",
              "      <td>0.332125</td>\n",
              "      <td>-0.213743</td>\n",
              "      <td>-0.117904</td>\n",
              "      <td>-0.191380</td>\n",
              "      <td>0.028687</td>\n",
              "      <td>0.224921</td>\n",
              "      <td>...</td>\n",
              "      <td>0.359925</td>\n",
              "      <td>-0.873016</td>\n",
              "      <td>0.141046</td>\n",
              "      <td>-0.459858</td>\n",
              "      <td>-0.790742</td>\n",
              "      <td>-0.382941</td>\n",
              "      <td>-0.352315</td>\n",
              "      <td>-0.261177</td>\n",
              "      <td>-0.500621</td>\n",
              "      <td>-0.901947</td>\n",
              "      <td>-0.382941</td>\n",
              "      <td>-0.747985</td>\n",
              "      <td>-0.391830</td>\n",
              "      <td>0.614840</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.187344</td>\n",
              "      <td>-0.476318</td>\n",
              "      <td>-0.802189</td>\n",
              "      <td>-0.601748</td>\n",
              "      <td>-0.691376</td>\n",
              "      <td>-0.648107</td>\n",
              "      <td>-0.723129</td>\n",
              "      <td>-0.549007</td>\n",
              "      <td>-0.601748</td>\n",
              "      <td>-0.929556</td>\n",
              "      <td>-0.586202</td>\n",
              "      <td>0.320269</td>\n",
              "      <td>-0.873016</td>\n",
              "      <td>0.230617</td>\n",
              "      <td>-0.285643</td>\n",
              "      <td>-0.649094</td>\n",
              "      <td>0.079392</td>\n",
              "      <td>-0.892303</td>\n",
              "      <td>0.939023</td>\n",
              "      <td>-0.067309</td>\n",
              "      <td>-0.779321</td>\n",
              "      <td>0.248037</td>\n",
              "      <td>0.046806</td>\n",
              "      <td>5</td>\n",
              "      <td>WALKING_UPSTAIRS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>0.280262</td>\n",
              "      <td>-0.018698</td>\n",
              "      <td>-0.109685</td>\n",
              "      <td>-0.996123</td>\n",
              "      <td>-0.998074</td>\n",
              "      <td>-0.991967</td>\n",
              "      <td>-0.996509</td>\n",
              "      <td>-0.997516</td>\n",
              "      <td>-0.992607</td>\n",
              "      <td>-0.939714</td>\n",
              "      <td>-0.577026</td>\n",
              "      <td>-0.823482</td>\n",
              "      <td>0.851158</td>\n",
              "      <td>0.693643</td>\n",
              "      <td>0.840339</td>\n",
              "      <td>-0.997394</td>\n",
              "      <td>-0.999975</td>\n",
              "      <td>-0.999988</td>\n",
              "      <td>-0.999860</td>\n",
              "      <td>-0.997109</td>\n",
              "      <td>-0.996239</td>\n",
              "      <td>-0.991663</td>\n",
              "      <td>-0.598011</td>\n",
              "      <td>-0.859599</td>\n",
              "      <td>-0.646639</td>\n",
              "      <td>0.385923</td>\n",
              "      <td>-0.241664</td>\n",
              "      <td>0.101185</td>\n",
              "      <td>0.190957</td>\n",
              "      <td>0.456281</td>\n",
              "      <td>-0.245810</td>\n",
              "      <td>0.311339</td>\n",
              "      <td>0.076550</td>\n",
              "      <td>0.424887</td>\n",
              "      <td>-0.179671</td>\n",
              "      <td>0.156384</td>\n",
              "      <td>-0.052179</td>\n",
              "      <td>-0.163751</td>\n",
              "      <td>0.216597</td>\n",
              "      <td>0.164204</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.684056</td>\n",
              "      <td>-0.747146</td>\n",
              "      <td>-0.949970</td>\n",
              "      <td>-0.996580</td>\n",
              "      <td>-0.997279</td>\n",
              "      <td>-0.997024</td>\n",
              "      <td>-0.997008</td>\n",
              "      <td>-0.997412</td>\n",
              "      <td>-0.996580</td>\n",
              "      <td>-0.999983</td>\n",
              "      <td>-0.996494</td>\n",
              "      <td>-0.956057</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.418893</td>\n",
              "      <td>-0.588401</td>\n",
              "      <td>-0.821342</td>\n",
              "      <td>-0.998563</td>\n",
              "      <td>-0.998383</td>\n",
              "      <td>-0.998003</td>\n",
              "      <td>-0.999262</td>\n",
              "      <td>-0.996855</td>\n",
              "      <td>-0.998563</td>\n",
              "      <td>-0.999995</td>\n",
              "      <td>-0.998056</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.428571</td>\n",
              "      <td>0.534796</td>\n",
              "      <td>-0.750003</td>\n",
              "      <td>-0.961720</td>\n",
              "      <td>0.740652</td>\n",
              "      <td>-0.003130</td>\n",
              "      <td>-0.288663</td>\n",
              "      <td>0.011929</td>\n",
              "      <td>0.768231</td>\n",
              "      <td>-0.467455</td>\n",
              "      <td>-0.519331</td>\n",
              "      <td>2</td>\n",
              "      <td>LAYING</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 563 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      tBodyAcc-mean()-X  tBodyAcc-mean()-Y  ...  subject          Activity\n",
              "2117           0.274369          -0.016706  ...       11            LAYING\n",
              "2937           0.260018          -0.008491  ...       16           SITTING\n",
              "6867           0.278964          -0.016177  ...       29            LAYING\n",
              "983            0.183580          -0.127213  ...        5  WALKING_UPSTAIRS\n",
              "61             0.280262          -0.018698  ...        2            LAYING\n",
              "\n",
              "[5 rows x 563 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq8WKe0x7SZc"
      },
      "source": [
        "## Preparando os Dados para os Modelos\n",
        "\n",
        "*   **x** = Todos os conjuntos de dados tirando as duas ultimas colunas.\n",
        "*   **y** = Ultima coluna, coluna que define a atividade.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTcaNixfDRD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21626fcd-a14e-4026-f152-251df1036262"
      },
      "source": [
        "# Separando os os dados do target\n",
        "x_train, y_train = train.iloc[:, :-2], train.iloc[:, -1:]\n",
        "x_validate, y_validate = validate.iloc[:, :-2], validate.iloc[:, -1:]\n",
        "x_test, y_test = test.iloc[:, :-2], test.iloc[:, -1:]\n",
        "print(f'Train: {x_train.shape}, {y_train.shape}\\nValidation: {x_validate.shape}, {y_validate.shape}\\nTraining: {x_test.shape}, {y_test.shape}\\n')"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (5149, 561), (5149, 1)\n",
            "Validation: (2575, 561), (2575, 1)\n",
            "Training: (2575, 561), (2575, 1)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPRbqoCVMZfd"
      },
      "source": [
        "Os modelos aceitam apenas números, então foi necessário alterar as strings que definem as classes para números."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_78axvFL4V_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54cbbf74-6637-4c17-cfeb-9292fa6ae4c9"
      },
      "source": [
        "# Trasformando as strings do target em números\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_validate = le.fit_transform(y_validate)\n",
        "y_test = le.fit_transform(y_test)\n",
        "\n",
        "# --------------Não sei oq é isso\n",
        "scaling_data = MinMaxScaler()\n",
        "x_train = scaling_data.fit_transform(x_train)\n",
        "x_validate = scaling_data.fit_transform(x_validate)\n",
        "x_test = scaling_data.transform(x_test)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6waF_f25De4J"
      },
      "source": [
        "# Multi-Layer Perceptron (MLP)\n",
        "\n",
        "Perceptron é utilizado para classificação binária, possuindo apenas 1 neurônio, sendo assim, não podendo se aplicar a dados não lineares. \n",
        "O MLP foi desenvolvido para suprir com essa limitação.Ele possui camadas de entrada e saída e uma ou mais camadas ocultas com muitos neurônios juntos. E enquanto no Perceptron o neurônio deve ter uma função de ativação que impõe um limite, como ReLU ou sigmoid, os neurônios em um MLP podem usar qualquer função de ativação arbitrária.\n",
        "\n",
        "Funções de ativação: \n",
        "*   **ReLU**: Função não linear que a não ativa todos os neurônios ao mesmo tempo. Se a entrada for negativa, ela será convertida em zero e o neurônio não será ativado. Isso significa que, ao mesmo tempo, apenas alguns neurônios são ativados, tornando a rede esparsa e eficiente e fácil para a computação.\n",
        "*   **Softmax**: Alternativa para função sigmóide para lidar com problemas de classificação, já que a mesma é capaz de lidar com mais de 2 classes, diferente da sigmóide.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmF9XuyDG6dz"
      },
      "source": [
        "# Criando o model\n",
        "model_mlp = Sequential()\n",
        "model_mlp.add(Dense(64, activation='relu', input_dim=x_train.shape[1])) # Layer 1\n",
        "model_mlp.add(Dropout(0.5))\n",
        "model_mlp.add(Dense(64, activation='relu')) # Layer 2\n",
        "model_mlp.add(Dropout(0.5))\n",
        "model_mlp.add(Dense(10, activation='softmax')) # Layer 3"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RosQCW8jXvQ-"
      },
      "source": [
        "\n",
        "\n",
        "*   **Compilação, Treino e validação**: O processo de treino foi composto por 20 epocas e 50% do dataset e a validação por 25% do dataset. \n",
        ">* Optimizer: [**Adam**](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) é um algoritmo de otimização que pode ser usado em vez do procedimento clássico de *Stochastic Gradient Descent* (mantém uma única taxa de aprendizado para todas as atualizações de peso e a taxa de aprendizado não muda durante o treinamento) para atualizar os pesos da rede iterativos com base nos dados de treinamento.\n",
        ">* Loss: [sparse_categorical_crossentropy](https://vitalflux.com/keras-categorical-cross-entropy-loss-function/) Usado para modelos de classificação multi-classes quando a output label  sao valores inteiros (0, 1, 2,..).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKw4bSSOXu1h",
        "outputId": "277b94de-969d-4924-bd9b-adf53c833b79"
      },
      "source": [
        "# Compilando o model e treinando\n",
        "model_mlp.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) # optimizer 'adam'\n",
        "history = model_mlp.fit(x_train, y_train, batch_size=64, epochs=20, validation_data=(x_validate, y_validate)) # teinando e validando "
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "81/81 [==============================] - 1s 6ms/step - loss: 1.5931 - accuracy: 0.3531 - val_loss: 0.9102 - val_accuracy: 0.7398\n",
            "Epoch 2/20\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.9931 - accuracy: 0.5605 - val_loss: 0.6210 - val_accuracy: 0.7685\n",
            "Epoch 3/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.7319 - accuracy: 0.6762 - val_loss: 0.5047 - val_accuracy: 0.8101\n",
            "Epoch 4/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.7318 - val_loss: 0.4017 - val_accuracy: 0.8559\n",
            "Epoch 5/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7720 - val_loss: 0.3463 - val_accuracy: 0.8707\n",
            "Epoch 6/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8079 - val_loss: 0.3097 - val_accuracy: 0.8664\n",
            "Epoch 7/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8320 - val_loss: 0.2783 - val_accuracy: 0.8816\n",
            "Epoch 8/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.3670 - accuracy: 0.8499 - val_loss: 0.2306 - val_accuracy: 0.9103\n",
            "Epoch 9/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.3591 - accuracy: 0.8578 - val_loss: 0.2270 - val_accuracy: 0.9169\n",
            "Epoch 10/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.3237 - accuracy: 0.8736 - val_loss: 0.2166 - val_accuracy: 0.9111\n",
            "Epoch 11/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.8808 - val_loss: 0.2519 - val_accuracy: 0.9064\n",
            "Epoch 12/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.3003 - accuracy: 0.8860 - val_loss: 0.2110 - val_accuracy: 0.9192\n",
            "Epoch 13/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.2731 - accuracy: 0.8998 - val_loss: 0.2031 - val_accuracy: 0.9208\n",
            "Epoch 14/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.2614 - accuracy: 0.9000 - val_loss: 0.1653 - val_accuracy: 0.9441\n",
            "Epoch 15/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.2514 - accuracy: 0.9093 - val_loss: 0.1609 - val_accuracy: 0.9324\n",
            "Epoch 16/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.2356 - accuracy: 0.9109 - val_loss: 0.1517 - val_accuracy: 0.9379\n",
            "Epoch 17/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.2072 - accuracy: 0.9225 - val_loss: 0.1353 - val_accuracy: 0.9503\n",
            "Epoch 18/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.2172 - accuracy: 0.9208 - val_loss: 0.1707 - val_accuracy: 0.9355\n",
            "Epoch 19/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.2022 - accuracy: 0.9305 - val_loss: 0.1326 - val_accuracy: 0.9495\n",
            "Epoch 20/20\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.2056 - accuracy: 0.9221 - val_loss: 0.1294 - val_accuracy: 0.9495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS_simmq8A4M"
      },
      "source": [
        "Testando o modelo com dataset de teste que equivale 50% do dataset total"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCqSvo7hjXl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774785e6-98f1-400e-d780-4ab443888672"
      },
      "source": [
        "# Testando o model após treinamento\n",
        "test_results = model_mlp.evaluate(x_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9588\n",
            "Test results - Loss: 0.12012684345245361 - Accuracy: 0.9588349461555481%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJRL8rJmkJaU"
      },
      "source": [
        "# Convolutional Neural Network (CNN)\n",
        "Uma **Artificial Neural Network (ANN)** é uma série de algoritmos que se esforçam para reconhecer relacionamentos subjacentes em um conjunto de dados, por meio de um processo que imita a maneira como o cérebro humano opera. As **ANN** podem se adaptar a mudanças de entrada para que a rede gere o melhor resultado possível sem a necessidade de redesenhar os critérios de saída.\n",
        "\n",
        "As **Convolutional Neural Network (CNN)** são um tipo especializado de ANN que usam convolução no lugar da multiplicação geral da matriz em pelo menos uma de suas camadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yD15rTtkP3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e478c43d-dfa0-41ff-99bc-5ca18976209c"
      },
      "source": [
        "n_timesteps, n_features, n_outputs = x_train.shape[0], x_train.shape[1], y_train.shape[0]\n",
        "\n",
        "# Adicionando mais uma dimensão a x, para ficarem 3, como é pedido no Conv1D\n",
        "x_train_cnn = x_train[..., None]\n",
        "x_validate_cnn = x_validate[..., None]\n",
        "\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=x_train_cnn.shape[1:]))\n",
        "model_cnn.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
        "model_cnn.add(Dropout(0.5))\n",
        "model_cnn.add(MaxPooling1D(pool_size=2))\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_cnn.fit(x_train_cnn, y_train, batch_size=64, epochs=20, validation_data=(x_validate_cnn, y_validate))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "81/81 [==============================] - 11s 127ms/step - loss: 0.8098 - accuracy: 0.6613 - val_loss: 0.4605 - val_accuracy: 0.8454\n",
            "Epoch 2/20\n",
            "81/81 [==============================] - 10s 124ms/step - loss: 0.2635 - accuracy: 0.8990 - val_loss: 0.2499 - val_accuracy: 0.9025\n",
            "Epoch 3/20\n",
            "81/81 [==============================] - 10s 124ms/step - loss: 0.1557 - accuracy: 0.9443 - val_loss: 0.1429 - val_accuracy: 0.9557\n",
            "Epoch 4/20\n",
            "81/81 [==============================] - 10s 124ms/step - loss: 0.1398 - accuracy: 0.9448 - val_loss: 0.1465 - val_accuracy: 0.9441\n",
            "Epoch 5/20\n",
            "81/81 [==============================] - 10s 125ms/step - loss: 0.0987 - accuracy: 0.9643 - val_loss: 0.0989 - val_accuracy: 0.9666\n",
            "Epoch 6/20\n",
            "81/81 [==============================] - 10s 125ms/step - loss: 0.1046 - accuracy: 0.9590 - val_loss: 0.1497 - val_accuracy: 0.9394\n",
            "Epoch 7/20\n",
            "81/81 [==============================] - 10s 124ms/step - loss: 0.1033 - accuracy: 0.9604 - val_loss: 0.1470 - val_accuracy: 0.9441\n",
            "Epoch 8/20\n",
            "81/81 [==============================] - 10s 123ms/step - loss: 0.0691 - accuracy: 0.9746 - val_loss: 0.1264 - val_accuracy: 0.9464\n",
            "Epoch 9/20\n",
            "81/81 [==============================] - 10s 126ms/step - loss: 0.0700 - accuracy: 0.9753 - val_loss: 0.1257 - val_accuracy: 0.9546\n",
            "Epoch 10/20\n",
            "81/81 [==============================] - 10s 125ms/step - loss: 0.0619 - accuracy: 0.9794 - val_loss: 0.0970 - val_accuracy: 0.9662\n",
            "Epoch 11/20\n",
            "81/81 [==============================] - 10s 125ms/step - loss: 0.0633 - accuracy: 0.9763 - val_loss: 0.0783 - val_accuracy: 0.9744\n",
            "Epoch 12/20\n",
            "81/81 [==============================] - 10s 124ms/step - loss: 0.0547 - accuracy: 0.9771 - val_loss: 0.0765 - val_accuracy: 0.9736\n",
            "Epoch 13/20\n",
            "81/81 [==============================] - 10s 125ms/step - loss: 0.0526 - accuracy: 0.9808 - val_loss: 0.0814 - val_accuracy: 0.9713\n",
            "Epoch 14/20\n",
            "81/81 [==============================] - 10s 123ms/step - loss: 0.0515 - accuracy: 0.9796 - val_loss: 0.0850 - val_accuracy: 0.9709\n",
            "Epoch 15/20\n",
            "81/81 [==============================] - 10s 124ms/step - loss: 0.0523 - accuracy: 0.9817 - val_loss: 0.1304 - val_accuracy: 0.9534\n",
            "Epoch 16/20\n",
            "81/81 [==============================] - 10s 123ms/step - loss: 0.0462 - accuracy: 0.9827 - val_loss: 0.0718 - val_accuracy: 0.9763\n",
            "Epoch 17/20\n",
            "81/81 [==============================] - 10s 124ms/step - loss: 0.0460 - accuracy: 0.9825 - val_loss: 0.0926 - val_accuracy: 0.9670\n",
            "Epoch 18/20\n",
            "81/81 [==============================] - 10s 123ms/step - loss: 0.0423 - accuracy: 0.9856 - val_loss: 0.1040 - val_accuracy: 0.9650\n",
            "Epoch 19/20\n",
            "81/81 [==============================] - 10s 124ms/step - loss: 0.0478 - accuracy: 0.9835 - val_loss: 0.0969 - val_accuracy: 0.9685\n",
            "Epoch 20/20\n",
            "81/81 [==============================] - 10s 123ms/step - loss: 0.0392 - accuracy: 0.9854 - val_loss: 0.0871 - val_accuracy: 0.9713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpZqaAIrt1pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56bb8bf6-c8e4-4fc2-d621-1b5d75160882"
      },
      "source": [
        "# Testando o model após treinamento\n",
        "x_test_cnn = x_test[..., None]\n",
        "test_results = model_cnn.evaluate(x_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81/81 [==============================] - 1s 15ms/step - loss: 0.0771 - accuracy: 0.9678\n",
            "Test results - Loss: 0.07712676376104355 - Accuracy: 0.9677670001983643%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcBUtkdcBNfY"
      },
      "source": [
        "# Recurrent Neural Network (RNN)\n",
        "\n",
        "**Recurrent Neural Network (RNN)** tem uma conexão recorrente no *hidden state*. Essa restrição de loop garante que as informações sequenciais sejam capturadas nos dados de entrada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJpQMVqfPWlw",
        "outputId": "3c317d97-2a7e-481e-c7c0-9492ad3e98bd"
      },
      "source": [
        "x_train_rnn = x_train[..., None]\n",
        "x_validate_rnn = x_validate[..., None]\n",
        "\n",
        "model_rnn2 = keras.models.Sequential()\n",
        "model_rnn2.add(keras.Input(shape=x_train_rnn.shape[1:])) \n",
        "model_rnn2.add(layers.SimpleRNN(128, return_sequences=True, activation='relu'))\n",
        "model_rnn2.add(Flatten())\n",
        "model_rnn2.add(layers.Dense(10))\n",
        "\n",
        "model_rnn2.summary()"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5149, 561, 1)\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_12 (SimpleRNN)   (None, 561, 128)          16640     \n",
            "                                                                 \n",
            " flatten_20 (Flatten)        (None, 71808)             0         \n",
            "                                                                 \n",
            " dense_130 (Dense)           (None, 10)                718090    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 734,730\n",
            "Trainable params: 734,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m13sO2U6Jn74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07c1bba7-f145-4909-edd4-f757e6f332cc"
      },
      "source": [
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optim = keras.optimizers.Adam(lr=0.001)\n",
        "metrics = [\"accuracy\"]\n",
        "\n",
        "model_rnn2.compile(loss=loss, optimizer=optim, metrics=metrics)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tav3miXhJuYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3aefd8a-a071-4a26-d5e6-6b6dba4952e5"
      },
      "source": [
        "model_rnn2.fit(\n",
        "    x_train_rnn, y_train, validation_data=(x_validate_rnn, y_validate), batch_size=64, epochs=10\n",
        ")"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "81/81 [==============================] - 23s 270ms/step - loss: 0.4360 - accuracy: 0.8194 - val_loss: 0.1771 - val_accuracy: 0.9243\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 22s 270ms/step - loss: 0.1289 - accuracy: 0.9503 - val_loss: 0.1358 - val_accuracy: 0.9429\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 22s 270ms/step - loss: 0.0735 - accuracy: 0.9720 - val_loss: 0.0765 - val_accuracy: 0.9736\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 22s 268ms/step - loss: 0.0638 - accuracy: 0.9765 - val_loss: 0.0839 - val_accuracy: 0.9701\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 22s 270ms/step - loss: 0.0515 - accuracy: 0.9821 - val_loss: 0.0986 - val_accuracy: 0.9612\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 22s 271ms/step - loss: 0.0577 - accuracy: 0.9779 - val_loss: 0.0982 - val_accuracy: 0.9604\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 22s 274ms/step - loss: 0.0336 - accuracy: 0.9880 - val_loss: 0.0686 - val_accuracy: 0.9771\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 22s 272ms/step - loss: 0.0308 - accuracy: 0.9883 - val_loss: 0.0646 - val_accuracy: 0.9755\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 22s 271ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.0732 - val_accuracy: 0.9748\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 22s 273ms/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 0.0829 - val_accuracy: 0.9697\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f225bb87210>"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoBTjecAVhia",
        "outputId": "b28483f4-b0db-4e4b-efe1-b4620cbda932"
      },
      "source": [
        "model_rnn2.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 - 4s - loss: 0.0759 - accuracy: 0.9740 - 4s/epoch - 88ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07594688981771469, 0.9739806056022644]"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEtTk01aGzlo"
      },
      "source": [
        "# Modelo Híbrido\n",
        "Criando modelo híbrido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8UCRcOOG34C",
        "outputId": "c64828fe-6462-4ba7-8347-cbfc4fa894ea"
      },
      "source": [
        "x_train = x_train[..., None]\n",
        "x_validate = x_validate[..., None]\n",
        "\n",
        "model_hyb = Sequential()\n",
        "# Model RNN\n",
        "model_hyb.add(keras.Input(shape=x_train_rnn.shape[1:])) \n",
        "model_hyb.add(layers.SimpleRNN(128, return_sequences=True, activation='relu'))\n",
        "# Model CNN\n",
        "model_hyb.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
        "model_hyb.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
        "model_hyb.add(Dropout(0.5))\n",
        "model_hyb.add(MaxPooling1D(pool_size=2))\n",
        "model_hyb.add(Flatten())\n",
        "# Model MLP\n",
        "model_hyb.add(Dense(64, activation='relu')) # Layer 1\n",
        "model_hyb.add(Dropout(0.5))\n",
        "model_hyb.add(Dense(64, activation='relu')) # Layer 2\n",
        "model_hyb.add(Dropout(0.5))\n",
        "model_hyb.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_hyb.summary()"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_13 (SimpleRNN)   (None, 561, 128)          16640     \n",
            "                                                                 \n",
            " conv1d_49 (Conv1D)          (None, 560, 64)           16448     \n",
            "                                                                 \n",
            " conv1d_50 (Conv1D)          (None, 559, 64)           8256      \n",
            "                                                                 \n",
            " dropout_73 (Dropout)        (None, 559, 64)           0         \n",
            "                                                                 \n",
            " max_pooling1d_17 (MaxPoolin  (None, 279, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten_21 (Flatten)        (None, 17856)             0         \n",
            "                                                                 \n",
            " dense_131 (Dense)           (None, 64)                1142848   \n",
            "                                                                 \n",
            " dropout_74 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_132 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_75 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,189,002\n",
            "Trainable params: 1,189,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoXcRTZd-PPG",
        "outputId": "35a5659f-a766-4bfb-a8dc-92a05c9e5f0e"
      },
      "source": [
        "model_hyb.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_hyb.fit(x_train, y_train, batch_size=64, epochs=20, validation_data=(x_validate, y_validate))"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "81/81 [==============================] - 38s 460ms/step - loss: 1.6232 - accuracy: 0.3484 - val_loss: 0.7208 - val_accuracy: 0.7984\n",
            "Epoch 2/20\n",
            "81/81 [==============================] - 37s 456ms/step - loss: 0.8176 - accuracy: 0.6564 - val_loss: 0.3642 - val_accuracy: 0.8808\n",
            "Epoch 3/20\n",
            "81/81 [==============================] - 37s 454ms/step - loss: 0.5569 - accuracy: 0.7609 - val_loss: 0.2314 - val_accuracy: 0.9142\n",
            "Epoch 4/20\n",
            "81/81 [==============================] - 37s 456ms/step - loss: 0.4441 - accuracy: 0.8157 - val_loss: 0.1939 - val_accuracy: 0.9344\n",
            "Epoch 5/20\n",
            "81/81 [==============================] - 37s 455ms/step - loss: 0.3685 - accuracy: 0.8458 - val_loss: 0.1631 - val_accuracy: 0.9437\n",
            "Epoch 6/20\n",
            "81/81 [==============================] - 37s 457ms/step - loss: 0.3160 - accuracy: 0.8699 - val_loss: 0.1688 - val_accuracy: 0.9239\n",
            "Epoch 7/20\n",
            "81/81 [==============================] - 37s 456ms/step - loss: 0.3045 - accuracy: 0.8811 - val_loss: 0.1104 - val_accuracy: 0.9573\n",
            "Epoch 8/20\n",
            "81/81 [==============================] - 37s 454ms/step - loss: 0.2810 - accuracy: 0.8910 - val_loss: 0.1341 - val_accuracy: 0.9538\n",
            "Epoch 9/20\n",
            "81/81 [==============================] - 37s 454ms/step - loss: 0.2570 - accuracy: 0.9004 - val_loss: 0.1205 - val_accuracy: 0.9530\n",
            "Epoch 10/20\n",
            "81/81 [==============================] - 37s 453ms/step - loss: 0.2231 - accuracy: 0.9145 - val_loss: 0.0759 - val_accuracy: 0.9724\n",
            "Epoch 11/20\n",
            "81/81 [==============================] - 37s 456ms/step - loss: 0.2078 - accuracy: 0.9254 - val_loss: 0.0805 - val_accuracy: 0.9736\n",
            "Epoch 12/20\n",
            "81/81 [==============================] - 37s 458ms/step - loss: 0.1965 - accuracy: 0.9279 - val_loss: 0.0812 - val_accuracy: 0.9709\n",
            "Epoch 13/20\n",
            "81/81 [==============================] - 37s 461ms/step - loss: 0.1907 - accuracy: 0.9256 - val_loss: 0.0840 - val_accuracy: 0.9713\n",
            "Epoch 14/20\n",
            "81/81 [==============================] - 37s 461ms/step - loss: 0.1802 - accuracy: 0.9276 - val_loss: 0.0755 - val_accuracy: 0.9736\n",
            "Epoch 15/20\n",
            "81/81 [==============================] - 37s 460ms/step - loss: 0.1877 - accuracy: 0.9262 - val_loss: 0.0744 - val_accuracy: 0.9748\n",
            "Epoch 16/20\n",
            "81/81 [==============================] - 37s 456ms/step - loss: 0.1770 - accuracy: 0.9332 - val_loss: 0.0786 - val_accuracy: 0.9658\n",
            "Epoch 17/20\n",
            "81/81 [==============================] - 37s 462ms/step - loss: 0.1587 - accuracy: 0.9369 - val_loss: 0.0791 - val_accuracy: 0.9709\n",
            "Epoch 18/20\n",
            "81/81 [==============================] - 37s 462ms/step - loss: 0.1549 - accuracy: 0.9367 - val_loss: 0.0682 - val_accuracy: 0.9740\n",
            "Epoch 19/20\n",
            "81/81 [==============================] - 37s 458ms/step - loss: 0.1623 - accuracy: 0.9394 - val_loss: 0.1137 - val_accuracy: 0.9538\n",
            "Epoch 20/20\n",
            "81/81 [==============================] - 37s 458ms/step - loss: 0.1552 - accuracy: 0.9379 - val_loss: 0.0833 - val_accuracy: 0.9666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm3-0v4OB3K4",
        "outputId": "dc973b7d-a6a1-4060-9c6c-8eefe231c125"
      },
      "source": [
        "# Testando o model após treinamento\n",
        "x_test_rnn2 = x_test[..., None]\n",
        "test_results = model_hyb.evaluate(x_test_rnn2, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81/81 [==============================] - 6s 75ms/step - loss: 0.0811 - accuracy: 0.9705\n",
            "Test results - Loss: 0.08111096173524857 - Accuracy: 0.9704854488372803%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hng_Xo0BhVxq"
      },
      "source": [
        "# Conclusão\n",
        "\n",
        "\n",
        "\n",
        "![image.png](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/table.png)"
      ]
    }
  ]
}