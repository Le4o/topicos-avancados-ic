{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Le4o/topicos-avancados-ic/blob/main/CNN_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCsplJkWbF7T"
      },
      "source": [
        "# PRATICA) Desenvolver uma rede neural convolucional para classificar a base de dados CIFAR-10. A rede necessariamente deve possuir:\n",
        "\n",
        "# 1)\t3 camadas convolucionais\n",
        "# 2)\tRealizar pooling a cada convolução\n",
        "# 3)\tO ultimo feature map deve ser menor que 7x7\n",
        "# 4)\tStride de 2 na primeira conv e de 1 nas demais\n",
        "# 5)\tPadding na primeira conv que evite a redução de dimensões e sem padding nas demais conv\n",
        "\n",
        "# W2 = (W1 - F)/S + 1\n",
        "# H2 = (H1 - F)/S + 1"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzLWUJnWdbxk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wMtsH-AcTAo"
      },
      "source": [
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t\n",
        "  # one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "  \n",
        "\treturn trainX, trainY, testX, testY"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itduIFyolG18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c1abd18-89d6-42aa-a4e4-8390c3902af2"
      },
      "source": [
        "trainX, trainY, testX, testY = load_dataset()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "170508288/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac6qFIDHry8N"
      },
      "source": [
        "batch_size = 32 \n",
        "n_classes = 10 \n",
        "epochs = 3\n",
        "\n",
        "height = trainX.shape[1]\n",
        "width = trainX.shape[2]\n",
        "\n",
        "trainX = trainX.astype('float32')\n",
        "trainX /= 255"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usYFNuJKBfj5",
        "outputId": "7e736a7d-6e03-4731-97fe-7768940fbf1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB-5OT0b8aXf"
      },
      "source": [
        "# Pooling\n",
        "\n",
        "# Feature Map\n",
        "\n",
        "# [Padding](https://www.geeksforgeeks.org/cnn-introduction-to-padding/) \n",
        "Padding é o processo de adicionar camadas de zeros na imagem de entrada para evitar o problema de perda de informação durante o processo de convolução."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKJyuvtFlGHR"
      },
      "source": [
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(ZeroPadding2D(padding=(16, 16)))\n",
        "  model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(height, width, 3), strides=2, padding='same', activation='relu')) # camada 1\n",
        "  model.add(MaxPooling2D(pool_size=(2,2))) # pooling 1\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=1, activation='relu', padding='valid')) # camada 2\n",
        "  model.add(MaxPooling2D(pool_size=(2,2))) # pooling 2\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=1, activation='relu', padding='valid')) # camada 3\n",
        "  model.add(MaxPooling2D(pool_size=(2,2))) # pooling 3\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVFJoF7RtQtX"
      },
      "source": [
        "def optimizer():\n",
        "    return SGD(learning_rate=1e-2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-pSinEfwyay",
        "outputId": "f9845645-1ee5-4531-e26a-e45628aec806"
      },
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer=optimizer(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(trainX, trainY, batch_size=batch_size, epochs=epochs, verbose=1)\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 102s 65ms/step - loss: 2.3028 - accuracy: 0.0992\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 100s 64ms/step - loss: 2.3028 - accuracy: 0.0977\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 102s 65ms/step - loss: 2.3027 - accuracy: 0.0964\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "zero_padding2d_2 (ZeroPaddin (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 5, 5, 32)          18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2, 2, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 66,090\n",
            "Trainable params: 66,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}