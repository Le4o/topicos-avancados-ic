{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Le4o/topicos-avancados-ic/blob/main/CNN_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCsplJkWbF7T"
      },
      "source": [
        "# PRATICA) Desenvolver uma rede neural convolucional para classificar a base de dados CIFAR-10. A rede necessariamente deve possuir:\n",
        "\n",
        "# 1)\t3 camadas convolucionais\n",
        "# 2)\tRealizar pooling a cada convolução\n",
        "# 3)\tO ultimo feature map deve ser menor que 7x7\n",
        "# 4)\tStride de 2 na primeira conv e de 1 nas demais\n",
        "# 5)\tPadding na primeira conv que evite a redução de dimensões e sem padding nas demais conv\n",
        "\n",
        "# W2 = (W1 - F)/S + 1\n",
        "# H2 = (H1 - F)/S + 1"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzLWUJnWdbxk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wMtsH-AcTAo"
      },
      "source": [
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t\n",
        "  # one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "  \n",
        "\treturn trainX, trainY, testX, testY"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itduIFyolG18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aacc0355-5bd8-4023-a364-635a74e10327"
      },
      "source": [
        "trainX, trainY, testX, testY = load_dataset()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "170508288/170498071 [==============================] - 11s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac6qFIDHry8N"
      },
      "source": [
        "batch_size = 32 \n",
        "n_classes = 10 \n",
        "epochs = 10\n",
        "\n",
        "height = trainX.shape[1]\n",
        "width = trainX.shape[2]\n",
        "\n",
        "trainX = trainX.astype('float32')\n",
        "trainX /= 255"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKJyuvtFlGHR"
      },
      "source": [
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(ZeroPadding2D(padding=(16, 16)))\n",
        "  model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(height, width, 3), strides=2, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=1, activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=1, activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVFJoF7RtQtX"
      },
      "source": [
        "def optimizer():\n",
        "    return SGD(learning_rate=1e-2)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-pSinEfwyay",
        "outputId": "1e9c32e1-aac0-45bd-fcb9-344515b66124"
      },
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer=optimizer(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(trainX, trainY, batch_size=batch_size, epochs=epochs, verbose=1)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 160s 102ms/step - loss: 2.1680 - accuracy: 0.1900\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 160s 102ms/step - loss: 1.9623 - accuracy: 0.2834\n",
            "Epoch 3/10\n",
            " 132/1563 [=>............................] - ETA: 2:26 - loss: 1.8708 - accuracy: 0.3127"
          ]
        }
      ]
    }
  ]
}